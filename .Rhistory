.groups = 'drop'
) %>%
filter(n_obs >= 10)  # Only show bins with enough data
ggplot(calibration_data, aes(x = mean_fitted, y = actual_success_rate)) +
geom_point(aes(size = n_obs), alpha = 0.7, color = "steelblue") +
geom_line(linewidth = 1, color = "darkblue") +
geom_abline(intercept = 0, slope = 1, color = "red",
linetype = "dashed", linewidth = 1.2) +
scale_size_continuous(name = "Sample Size", range = c(3, 10)) +
labs(title = "Model Calibration: Predicted vs Actual Success Rate",
subtitle = "Points on red line = perfect calibration",
x = "Mean Predicted Probability",
y = "Actual Success Rate") +
coord_fixed(ratio = 1, xlim = c(0, 1), ylim = c(0, 1)) +
theme_minimal() +
theme(plot.title = element_text(hjust = 0.5, face = "bold"),
plot.subtitle = element_text(hjust = 0.5))
# Option 2: ROC-style cumulative plot
interval_data_sorted = interval_data %>%
arrange(fitted_prob) %>%
mutate(
obs_number = row_number(),
cumulative_fitted = cummean(fitted_prob),
cumulative_actual = cummean(Success)
)
ggplot(interval_data_sorted, aes(x = obs_number)) +
geom_line(aes(y = cumulative_actual, color = "Actual (Cumulative Avg)"),
linewidth = 1.2) +
geom_line(aes(y = cumulative_fitted, color = "Fitted (Cumulative Avg)"),
linewidth = 1.2) +
scale_color_manual(name = "Value",
values = c("Actual (Cumulative Avg)" = "red",
"Fitted (Cumulative Avg)" = "blue")) +
labs(title = "Cumulative Average: Actual vs Fitted",
subtitle = "Observations sorted by fitted probability",
x = "Observation (sorted by fitted probability)",
y = "Cumulative Average") +
theme_minimal() +
theme(plot.title = element_text(hjust = 0.5, face = "bold"),
legend.position = "bottom")
# Option 3: Decile plot (common in practice)
interval_data$decile = ntile(interval_data$fitted_prob, 10)
decile_data = interval_data %>%
group_by(decile) %>%
summarise(
mean_fitted = mean(fitted_prob),
actual_rate = mean(Success),
n = n(),
.groups = 'drop'
)
ggplot(decile_data, aes(x = mean_fitted, y = actual_rate)) +
geom_line(linewidth = 1, color = "darkblue") +
ggplot(decile_data, aes(x = mean_fitted, y = actual_rate)) +
geom_point(aes(size = n), color = "steelblue", alpha = 0.7) +
geom_line(linewidth = 1, color = "darkblue") +
geom_abline(intercept = 0, slope = 1, color = "red",
linetype = "dashed", linewidth = 1.2) +
geom_text(aes(label = decile), vjust = -1, size = 3) +
scale_size_continuous(name = "Sample Size") +
labs(title = "Decile Calibration Plot",
subtitle = "Each point represents 10% of predictions (by decile)",
x = "Mean Predicted Probability",
y = "Actual Success Rate") +
theme_minimal() +
theme(plot.title = element_text(hjust = 0.5, face = "bold"))
ggplot(decile_data, aes(x = mean_fitted, y = actual_rate)) +
geom_point(aes(size = n), color = "steelblue", alpha = 0.7) +
geom_line(linewidth = 1, color = "darkblue") +
geom_abline(intercept = 0, slope = 1, color = "red",
linetype = "dashed", linewidth = 1.2) +
geom_text(aes(label = decile), vjust = -1, size = 3) +
scale_size_continuous(name = "Sample Size") +
labs(title = "Decile Calibration Plot",
subtitle = "Each point represents 10% of predictions (by decile)",
x = "Mean Predicted Probability",
y = "Actual Success Rate") +
theme_minimal() +
theme(plot.title = element_text(hjust = 0.5, face = "bold"))
ggplot(interval_data_sorted, aes(x = obs_number)) +
geom_line(aes(y = cumulative_actual, color = "Actual (Cumulative Avg)"),
linewidth = 1.2) +
geom_line(aes(y = cumulative_fitted, color = "Fitted (Cumulative Avg)"),
linewidth = 1.2) +
scale_color_manual(name = "Value",
values = c("Actual (Cumulative Avg)" = "red",
"Fitted (Cumulative Avg)" = "blue")) +
labs(title = "Cumulative Average: Actual vs Fitted",
subtitle = "Observations sorted by fitted probability",
x = "Observation (sorted by fitted probability)",
y = "Cumulative Average") +
theme_minimal() +
theme(plot.title = element_text(hjust = 0.5, face = "bold"),
legend.position = "bottom")
ggplot(interval_data, aes(x = fitted_prob, y = Success)) +
geom_jitter(alpha = 0.3, width = 0, height = 0.05, color = "steelblue") +
geom_smooth(method = "loess", se = TRUE, color = "red", linewidth = 1.5) +
geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "darkgreen") +
labs(title = "Actual vs Fitted Probabilities",
subtitle = "Red line shows actual relationship, green line is perfect prediction",
x = "Fitted Probability",
y = "Actual Outcome (0 or 1)") +
theme_minimal() +
theme(plot.title = element_text(hjust = 0.5, face = "bold"))
# Coefficient interpretation
summary(best_model)
exp(coef(best_model))  # Exponentiate for odds ratios
# Add this to your existing graph code
library(ggpubr)
install.packages("ggpubr")
# Add this to your existing graph code
library(ggpubr)
# Coefficient interpretation
summary(best_model)
exp(coef(best_model))  # Exponentiate for odds ratios
# Add this to your existing graph code
library(ggpubr)
# Or calculate manually and add as annotation
cor_test = cor.test(daily_overall_success$DayNum, daily_overall_success$overall_success_rate)
# Example: Predict success on Day 21, Interval 8
new_data = data.frame(DayNum = 21, Interval = 8)
predict(best_model, newdata = new_data, type = "response")
confint(best_model)
# Compare all models
model_comparison = data.frame(
Model = c("Null", "Additive", "Full", "Best (Stepwise)"),
AIC = c(AIC(cloglog_null), AIC(cloglog_time), AIC(cloglog_full), AIC(best_model)),
Pseudo_R2 = c(0,
1 - cloglog_time$deviance/cloglog_time$null.deviance,
1 - cloglog_full$deviance/cloglog_full$null.deviance,
pseudo_r2)
)
kable(model_comparison)
summary(best_model)
summary(cloglog_full)
summary(best_model)
decile_data = interval_data %>%
group_by(decile) %>%
summarise(
mean_fitted = mean(fitted_prob),
actual_rate = mean(Success),
n = n(),
.groups = 'drop'
)
# 1. Generate predictions for existing world_data
world_data $predicted_prob = predict(firth_simple, type = "response")
# 1. Generate predictions for existing world_data
world_data$predicted_prob = predict(firth_simple, type = "response")
firth_simple = logistf(W8_4 ~ success_rate, world_data  = world_data )
world_data
firth_simple = logistf(W8_4 ~ success_rate, data  = world_data )
summary(firth_simple)
# 1. Generate predictions for existing world_data
world_data $predicted_prob = predict(firth_simple, type = "response")
# 2. DIAGNOSTIC PLOT 3: Success rate vs probability curve
ggplot(world_data , aes(x = success_rate, y = predicted_prob)) +
geom_point(aes(color = as.factor(W8_4)), alpha = 0.5) +
geom_smooth(method = "loess", se = TRUE, color = "blue") +
labs(title = "Success Rate vs Predicted Probability",
x = "Success Rate (prior levels)",
y = "Predicted Probability of World Record",
color = "Actual WR") +
scale_color_manual(values = c("0" = "red", "1" = "green"),
labels = c("No WR", "WR")) +
theme_minimal()
# 3.goodness of fit
hoslem.test(world_data $W8_4, world_data $predicted_prob, g = 10)
cat("Test: p >0.05 indicates good fit\n")
target_row = world_data [
world_data $W1_1 == 1 &
world_data $W1_2 == 1 &
world_data $W4_1 == 1 &
world_data $W4_2 == 1 &
world_data $W8_1 == 1 &
world_data $W8_2 == 1 &
world_data $W8_3 == 1,
]
target_row
world_data
interval_data = read.csv("FINAL DATA.csv")
interval_data
#Read in world_data  (world_data  is ordered)
world_data   = read.csv("FINAL WORLD DATA.csv")
# Create composite features
world_data  = world_data  %>%
mutate(
# Overall success rate up to W8_3
success_rate = (W1_1 + W1_2 + W4_1 + W4_2 + W8_1 + W8_2 + W8_3) / 7
)
world_data
interval_data = interval_data   %>%
mutate(DayNum = as.numeric(gsub('Day_', '', Day)))
world_data = world_data  %>%
mutate(DayNum = as.numeric(gsub('Day_', '', Day)))
# Calculate success rate by day and interval
daily_interval_success = interval_data   %>%
group_by(DayNum, Interval) %>%
summarise(
success_rate = mean(Success),
n_attempts = n(),
.groups = 'drop'
)
# Calculate overall success rate by day (across all intervals)
daily_overall_success = interval_data   %>%
group_by(DayNum) %>%
summarise(
overall_success_rate = mean(Success),
total_attempts = n(),
.groups = 'drop'
)
# Calculate how far Nifski get on average each day
daily_progression = interval_data   %>%
group_by(DayNum, Run) %>%
summarise(
max_interval_reached = max(Interval[Success == 1]),
.groups = 'drop'
) %>%
group_by(DayNum) %>%
summarise(
avg_max_interval = mean(max_interval_reached),
median_max_interval = median(max_interval_reached),
.groups = 'drop'
)
# Graph 1: Overall Success Rate Over Time (Enhanced with Legend)
ggplot(daily_overall_success, aes(x = DayNum, y = overall_success_rate)) +
geom_point(aes(color = "Daily Success Rate"), size = 4, alpha = 0.7) +
geom_smooth(aes(color = "Smoothed Trend"),
method = "loess", se = FALSE, linewidth = 1.5) +
geom_smooth(aes(color = "Linear Trend"),
method = "lm", se = TRUE, linewidth = 1.2, alpha = 0.2) +
scale_color_manual(name = "Legend",
values = c("Daily Success Rate" = "steelblue",
"Smoothed Trend" = "darkblue",
"Linear Trend" = "red")) +
scale_y_continuous(labels = scales::percent_format(accuracy = 1),
limits = c(0.50, 0.70)) +
scale_x_continuous(breaks = seq(0, 21, by = 3)) +
labs(title = "Speedrun Performance Improvement Over Time",
subtitle = "Overall success rate across all intervals by day",
x = "Day",
y = "Success Rate") +
theme_minimal(base_size = 13) +
theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 16),
plot.subtitle = element_text(hjust = 0.5, size = 12, color = "gray30"),
panel.grid.minor = element_blank(),
axis.title = element_text(face = "bold"),
legend.position = "right")
#Now that we've shown that there is improvement
# Model improvement over time on interval completion
cloglog_time = glm(Success ~ DayNum + factor(Interval),
data = interval_data,
family = binomial(link = "cloglog"))
summary(cloglog_time)
cloglog_full = glm(Success ~ DayNum * factor(Interval),
data = interval_data,
family = binomial(link = "cloglog"))
anova(cloglog_time, cloglog_full, test = "Chisq")
#saturated model is better so do stepwise to find best AIC
# Null model (intercept only)
cloglog_null = glm(Success ~ 1,
data = interval_data,
family = binomial(link = "cloglog"))
# Forward stepwise selection
forward_model = step(cloglog_null,
scope = list(lower = cloglog_null, upper = cloglog_full),
direction = "forward",
trace = 0)
# Backward stepwise selection
backward_model = step(cloglog_full,
direction = "backward",
trace = 0)
# Both directions stepwise selection
both_model = step(cloglog_null,
scope = list(lower = cloglog_null, upper = cloglog_full),
direction = "both",
trace = 0)
best_model = forward_model
summary(best_model)
#Best model is Success ~ factor(Interval) + DayNum + factor(Inveral):DayNum
# Analyze best_model fit
cat("P-value:", deviance_gof, "\n")
cat("Interpretation: p >0.05 indicates good fit\n")
# 3. Pearson Chi-Square Test
pearson_resid = residuals(best_model, type = "pearson")
pearson_chisq = sum(pearson_resid^2)
pearson_pval = 1 - pchisq(pearson_chisq, best_model$df.residual)
cat("\nPearson Chi-Square Test:\n")
cat("Chi-Square:", pearson_chisq, "\n")
cat("P-value:", pearson_pval, "\n")
# 4. Hosmer-Lemeshow Test
library(ResourceSelection)
hl_test = hoslem.test(interval_data$Success, fitted(best_model), g = 10)
print(hl_test)
cat("Hosmer-Lemeshow: p >0.05 indicates good fit\n")
# 5. McFadden's Pseudo R-squared
null_dev = best_model$null.deviance
resid_dev = best_model$deviance
pseudo_r2 = 1 - (resid_dev / null_dev)
cat("\nMcFadden's Pseudo R-squared:", pseudo_r2, "\n")
cat("Interpretation: 0.2-0.4 = excellent fit\n")
# 6. Calculate VIF for multicollinearity (if applicable)
cat("\nVariance Inflation Factors:\n")
vif_values = vif(best_model)
print(vif_values)
cat("VIF < 10 indicates no serious multicollinearity\n")
# 7. GRAPHS
# Graph 3: Residuals by Interval
ggplot(interval_data, aes(x = factor(Interval), y = deviance_resid)) +
geom_boxplot(fill = "lightblue", alpha = 0.7) +
geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
labs(title = "Residuals by Interval",
subtitle = "Checking if residuals vary by interval level",
x = "Interval",
y = "Deviance Residuals") +
theme_minimal() +
theme(plot.title = element_text(hjust = 0.5, face = "bold"))
ggplot(interval_data, aes(x = factor(Interval), y = deviance_resid)) +
geom_boxplot(fill = "lightblue", alpha = 0.7) +
geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
labs(title = "Residuals by Interval",
subtitle = "Checking if residuals vary by interval level",
x = "Interval",
y = "Deviance Residuals") +
theme_minimal() +
theme(plot.title = element_text(hjust = 0.5, face = "bold"))
# Get fitted probabilities for each observation from best_model
interval_data$stage_fitted_prob = fitted(best_model)
# Aggregate to run level - average predicted success across all stages
run_level_predictions = interval_data %>%
group_by(Run, Day, DayNum) %>%
summarise(
avg_predicted_success = mean(stage_fitted_prob),
min_predicted_success = min(stage_fitted_prob),  # weakest stage
.groups = 'drop'
)
# Merge with world_data
world_data = world_data %>%
left_join(run_level_predictions, by = c("Day", "DayNum"))
# Now use in your WR model
cloglog_wr_enhanced = glm(W8_4 ~ success_rate + avg_predicted_success + DayNum,
data = world_data,
family = binomial(link = "cloglog"))
summary(cloglog_wr_enhanced)
# Try the simplest model
cloglog_simple = glm(W8_4 ~ DayNum,
data = world_data,
family = binomial(link = "cloglog"))
# Try the simplest model
cloglog_simple = glm(W8_4 ~ DayNum,
data = world_data,
family = binomial(link = "cloglog"))
summary(cloglog_simple)
# Try with just success_rate and DayNum (no avg_predicted_success)
cloglog_two = glm(W8_4 ~ success_rate + DayNum,
data = world_data,
family = binomial(link = "cloglog"))
summary(cloglog_wr_enhanced)
summary(cloglog_simple)
summary(cloglog_two)
summary(cloglog_two)
# Test if improvement rate depends on skill level
cloglog_interaction = glm(W8_4 ~ success_rate * DayNum,
data = world_data,
family = binomial(link = "cloglog"))
AIC(cloglog_interaction)  # Compare to 1022.5
summary(cloglog_interaction)
# Get coefficients for DayNum interaction with each interval
coef_summary = summary(best_model)$coefficients
# Extract interaction terms
interaction_coefs = coef_summary[grepl("DayNum:factor", rownames(coef_summary)), ]
# Create interval-specific improvement rates
interval_improvement = data.frame(
Interval = 2:8,
improvement_rate = interaction_coefs[, "Estimate"]
)
# Get coefficients
coef_summary = summary(best_model)$coefficients
# Check what the interaction terms are actually called
print(rownames(coef_summary))
# Extract interaction terms - try different pattern
interaction_coefs = coef_summary[grepl("factor.*:DayNum|DayNum:factor", rownames(coef_summary)), ]
# If still empty, check the exact names
if(nrow(interaction_coefs) == 0) {
# Print all coefficient names to see the pattern
print("Coefficient names:")
print(rownames(coef_summary))
# Try this pattern instead
interaction_coefs = coef_summary[grepl(":DayNum", rownames(coef_summary)), ]
}
print("Interaction coefficients:")
print(interaction_coefs)
# Now create the data frame (adjust length as needed)
if(nrow(interaction_coefs) > 0) {
interval_improvement = data.frame(
Interval = 2:(1 + nrow(interaction_coefs)),
improvement_rate = interaction_coefs[, "Estimate"]
)
print(interval_improvement)
# Calculate weighted improvement score
world_data = world_data %>%
mutate(
weighted_improvement =
W1_1 * 0 +  # baseline (Interval 1 has no interaction term)
W1_2 * interval_improvement$improvement_rate[1] +
W4_1 * interval_improvement$improvement_rate[2] +
W4_2 * interval_improvement$improvement_rate[3] +
W8_1 * interval_improvement$improvement_rate[4] +
W8_2 * interval_improvement$improvement_rate[5] +
W8_3 * interval_improvement$improvement_rate[6]
)
# Use in model
firth_improved = logistf(W8_4 ~ success_rate + weighted_improvement + DayNum,
data = world_data)
summary(firth_improved)
} else {
cat("No interaction terms found. Check your best_model formula.\n")
cat("Your model should be: Success ~ DayNum * factor(Interval)\n")
}
summary(firth_improved)
firth_weighted_only = logistf(W8_4 ~ weighted_improvement,
data = world_data)
summary(firth_weighted_only)
# Best World Record Prediction Model
best_wr_model = glm(W8_4 ~ success_rate + DayNum,
data = world_data,
family = binomial(link = "cloglog"))
summary(best_wr_model)
# Check AIC
AIC(best_wr_model)
# Make predictions
world_data$wr_predicted_prob = predict(best_wr_model, type = "response")
# Example: Predict for perfect run on Day 22
perfect_run = data.frame(
success_rate = 1.0,
DayNum = 22
)
predict(best_wr_model, newdata = perfect_run, type = "response")
# Best World Record Prediction Model
best_wr_model = glm(W8_4 ~ success_rate + DayNum,
data = world_data,
family = binomial(link = "cloglog"))
summary(best_wr_model)
# Check AIC
AIC(best_wr_model)
# Make predictions
world_data$wr_predicted_prob = predict(best_wr_model, type = "response")
# Example: Predict for perfect run on Day 22
perfect_run = data.frame(
success_rate = 1.0,
DayNum = 22
)
predict(best_wr_model, newdata = perfect_run, type = "response")
world_data
best_wr_model = glm(W8_4 ~ success_rate + DayNum,
ziformula = ~ success_rate + DayNum,
data = world_data,
family = binomial(link = "cloglog"))
best_wr_model = glm(W8_4 ~ success_rate + DayNum,
ziformula = ~ success_rate + DayNum,
data = world_data,
family = binomial(link = "logit"))
best_wr_model = glmmTMB(W8_4 ~ success_rate + DayNum,
ziformula = ~ success_rate + DayNum,
data = world_data,
family = binomial(link = "cloglog"))
summary(best_wr_model)
best_wr_model = glmmTMB(W8_4 ~ success_rate + DayNum,
ziformula = ~ DayNum,
data = world_data,
family = binomial(link = "cloglog"))
summary(best_wr_model)
best_wr_model = glm(W8_4 ~ success_rate + DayNum,
data = world_data,
family = binomial(link = "cloglog"))
summary(best_wr_model)
best_wr_model2 = glm(W8_4 ~  DayNum,
data = world_data,
family = binomial(link = "cloglog"))
summary(best_wr_model2)
anova(best_wr_model2, best_wr_model)
AIC(best_wr_model)
AIC(best_wr_model2)
coef(best_wr_model)
logLik(best_wr_model2)
logLik(best_wr_model)
best_wr_model2 = glm(W8_4 ~  success_rate,
data = world_data,
family = binomial(link = "cloglog"))
summary(best_wr_model2)
AIC(best_wr_model)
best_wr_model = glm(W8_4 ~ success_rate + DayNum,
data = world_data,
family = binomial(link = "logit"))
best_wr_model2 = glm(W8_4 ~  DayNum,
data = world_data,
family = binomial(link = "logit"))
summary(best_wr_model)
summary(best_wr_model2)
world_data$success_rate
world_data$success_rate %>% summarize(.)
world_data$success_rate %>% summary(.)
hist(world_data$success_rate)
best_wr_model2 = glm(W8_4 ~  success_rate,
data = world_data,
family = binomial(link = "logit"))
summary(best_wr_model2)
test<- model.matrix(lm(~success_rate,data=world_data))
world_data %>% group_by(W8_4) %>% summary(avg=mean(success_rate))
world_data %>% group_by(W8_4) %>% summarize(avg=mean(success_rate))
successes<-world_data %>% filter(W8_4==1)
hist(successes$success_rate)
not_success<-world_data %>% filter(W8_4!=1)
max(not_success$success_rate)
