model_comparison$Model <- factor(model_comparison$Model,
levels = c("Null", "Logistic\n(Day + Int)",
"CLogLog\n(Day + Int)", "CLogLog\n(Day × Int)"))
p6 <- ggplot(model_comparison, aes(x = Model, y = AIC, fill = Model)) +
geom_col(alpha = 0.8) +
geom_text(aes(label = format(AIC, big.mark = ",")),
vjust = -0.5, size = 5, fontface = "bold") +
scale_fill_manual(values = c("gray60", "#3498db", "#3498db", "#e74c3c")) +
labs(title = "Model Selection: AIC Comparison",
subtitle = "Lower AIC indicates better fit",
x = "Model Specification",
y = "AIC (Akaike Information Criterion)") +
theme_minimal(base_size = 13) +
theme(plot.title = element_text(face = "bold", hjust = 0.5, size = 15),
plot.subtitle = element_text(hjust = 0.5),
legend.position = "none",
axis.text.x = element_text(size = 11))
ggsave("model_comparison_aic.png", plot = p6, width = 9, height = 6, dpi = 300)
cat("✓ Created model_comparison_aic.png\n")
# ============================================================================
# FIGURE 7: Practice Time Allocation Recommendation
# ============================================================================
practice_priority <- data.frame(
Interval = 1:8,
Baseline_Success = c(0.973, 0.881, 0.764, 0.628, 0.512, 0.435, 0.357, 0.289),
Improvement_Rate = c(0.0347, 0.0347-0.0185, 0.0347-0.0092, 0.0347+0.0043,
0.0347+0.0168, 0.0347+0.0221, 0.0347+0.0195, 0.0347+0.0195),
Priority = c("Low", "Low", "Low", "Medium", "High", "High", "High", "Highest")
)
practice_priority$Priority <- factor(practice_priority$Priority,
levels = c("Low", "Medium", "High", "Highest"))
p7 <- ggplot(practice_priority, aes(x = factor(Interval), y = Improvement_Rate, fill = Priority)) +
geom_col(alpha = 0.8) +
geom_text(aes(label = Priority), vjust = -0.5, size = 4, fontface = "bold") +
scale_fill_manual(values = c("Low" = "gray70", "Medium" = "#f39c12",
"High" = "#e67e22", "Highest" = "#e74c3c")) +
labs(title = "Optimal Practice Allocation by Interval",
subtitle = "Focus on intervals with highest improvement potential",
x = "Interval",
y = "Daily Improvement Rate (log-odds scale)",
fill = "Practice Priority") +
theme_minimal(base_size = 13) +
theme(plot.title = element_text(face = "bold", hjust = 0.5, size = 15),
plot.subtitle = element_text(hjust = 0.5),
legend.position = "right")
ggsave("practice_allocation.png", plot = p7, width = 10, height = 6, dpi = 300)
cat("✓ Created practice_allocation.png\n")
# ============================================================================
# Summary
# ============================================================================
cat("\n========================================\n")
cat("ALL FIGURES GENERATED SUCCESSFULLY!\n")
cat("========================================\n\n")
cat("Figures saved to:", getwd(), "\n\n")
cat("Figure Recommendations:\n\n")
cat("1. methodology_overview.png - Two-stage modeling approach\n")
cat("2. coefficient_plot.png - Interaction effects with CI\n")
cat("3. wr_probability_progression.png - WR probability over time\n")
cat("4. wr_historical_progression.png - Historical WR evolution\n")
cat("5. interval_difficulty_cascade.png - Difficulty visualization\n")
cat("6. model_comparison_aic.png - Model selection comparison\n")
cat("7. practice_allocation.png - Practice recommendations\n")
# Get the exact coefficient and predicted probabilities
coef(interval_models[["W4_1"]])
# Calculate actual change over 21 days
pred_change <- predict(interval_models[["W4_1"]],
newdata = data.frame(DayNum = 21),
type = "response") -
predict(interval_models[["W4_1"]],
newdata = data.frame(DayNum = 1),
type = "response")
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE,
fig.width = 6, fig.height = 4)
library(tidyverse)
library(knitr)
library(readxl)
library(MASS)
library(dplyr)
library(car)
library(broom)
library(GGally)
library(glmmTMB)
library(logistf)
library(ggplot2)
library(ResourceSelection)
interval_data = read.csv("FINAL DATA.csv")
#interval_data
#Read in world_data  (world_data  is ordered)
world_data   = read.csv("FINAL WORLD DATA.csv")
#world_data
interval_data = interval_data   %>%
mutate(DayNum = as.numeric(gsub('Day_', '', Day)))
world_data = world_data  %>%
mutate(DayNum = as.numeric(gsub('Day_', '', Day)))
# Calculate success rate by day and interval
daily_interval_success = interval_data   %>%
group_by(DayNum, Interval) %>%
summarise(
success_rate = mean(Success),
n_attempts = n(),
.groups = 'drop'
)
# Calculate overall success rate by day (across all intervals)
daily_overall_success = interval_data   %>%
group_by(DayNum) %>%
summarise(
overall_success_rate = mean(Success),
total_attempts = n(),
.groups = 'drop'
)
# Calculate how far Nifski get on average each day
daily_progression = interval_data   %>%
group_by(DayNum, Run) %>%
summarise(
max_interval_reached = max(Interval[Success == 1]),
.groups = 'drop'
) %>%
group_by(DayNum) %>%
summarise(
avg_max_interval = mean(max_interval_reached),
median_max_interval = median(max_interval_reached),
.groups = 'drop'
)
#interval_data
# Graph 1: Overall Success Rate Over Time (Enhanced with Legend)
ggplot(daily_overall_success, aes(x = DayNum, y = overall_success_rate)) +
geom_point(aes(color = "Daily Success Rate"), size = 4, alpha = 0.7) +
geom_smooth(aes(color = "Smoothed Trend"),
method = "loess", se = FALSE, linewidth = 1.5) +
geom_smooth(aes(color = "Linear Trend"),
method = "lm", se = TRUE, linewidth = 1.2, alpha = 0.2) +
scale_color_manual(name = "Legend",
values = c("Daily Success Rate" = "steelblue",
"Smoothed Trend" = "darkblue",
"Linear Trend" = "red")) +
scale_y_continuous(labels = scales::percent_format(accuracy = 1),
limits = c(0.50, 0.70)) +
scale_x_continuous(breaks = seq(0, 21, by = 3)) +
labs(title = "Speedrun Performance Improvement Over Time",
subtitle = "Overall success rate across all intervals by day",
x = "Day",
y = "Success Rate") +
theme_minimal(base_size = 13) +
theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 16),
plot.subtitle = element_text(hjust = 0.5, size = 12, color = "gray30"),
panel.grid.minor = element_blank(),
axis.title = element_text(face = "bold"),
legend.position = "right")
#Now that we've shown that there is improvement
# Model improvement over time on interval completion
cloglog_time = glm(Success ~ DayNum + factor(Interval),
data = interval_data,
family = binomial(link = "cloglog"))
summary(cloglog_time)
cloglog_full = glm(Success ~ DayNum * factor(Interval),
data = interval_data,
family = binomial(link = "cloglog"))
anova(cloglog_time, cloglog_full, test = "Chisq")
#saturated model is better so do stepwise to find best AIC
# Null model (intercept only)
cloglog_null = glm(Success ~ 1,
data = interval_data,
family = binomial(link = "cloglog"))
# Forward stepwise selection
forward_model = step(cloglog_null,
scope = list(lower = cloglog_null, upper = cloglog_full),
direction = "forward",
trace = 0)
# Backward stepwise selection
backward_model = step(cloglog_full,
direction = "backward",
trace = 0)
# Both directions stepwise selection
both_model = step(cloglog_null,
scope = list(lower = cloglog_null, upper = cloglog_full),
direction = "both",
trace = 0)
best_model = forward_model
summary(best_model)
#Best model is Success ~ factor(Interval) + DayNum + factor(Inveral):DayNum
#Now that we've shown that there is improvement
# Model improvement over time on interval completion
cloglog_time = glm(Success ~ DayNum + factor(Interval),
data = interval_data,
family = binomial(link = "cloglog"))
summary(cloglog_time)
cloglog_full = glm(Success ~ DayNum * factor(Interval),
data = interval_data,
family = binomial(link = "cloglog"))
anova(cloglog_time, cloglog_full, test = "Chisq")
#saturated model is better so do stepwise to find best AIC
# Null model (intercept only)
cloglog_null = glm(Success ~ 1,
data = interval_data,
family = binomial(link = "cloglog"))
# Forward stepwise selection
forward_model = step(cloglog_null,
scope = list(lower = cloglog_null, upper = cloglog_full),
direction = "forward",
trace = 0)
# Backward stepwise selection
backward_model = step(cloglog_full,
direction = "backward",
trace = 0)
# Both directions stepwise selection
both_model = step(cloglog_null,
scope = list(lower = cloglog_null, upper = cloglog_full),
direction = "both",
trace = 0)
best_model = forward_model
summary(best_model)
#Best model is Success ~ factor(Interval) + DayNum + factor(Inveral):DayNum
# Initialize empty list
interval_models = list()
# Map intervals to their corresponding world record columns
interval_mapping = c(
"1" = "W1_1",
"2" = "W1_2",
"3" = "W4_1",
"4" = "W4_2",
"5" = "W8_1",
"6" = "W8_2",
"7" = "W8_3",
"8" = "W8_4"
)
# Build models for intervals 1-7 (we're predicting interval 8/W8_4)
for (interval_num in 1:7) {
cat("\n=== Processing Interval", interval_num, "(", interval_mapping[as.character(interval_num)], ") ===\n")
# Filter data for this specific interval
interval_subset = interval_data %>%
filter(Interval == interval_num)
cat("Number of observations:", nrow(interval_subset), "\n")
cat("Success rate:", mean(interval_subset$Success), "\n")
# Build cloglog model for this interval
model = glm(Success ~ DayNum,
data = interval_subset,
family = binomial(link = "cloglog"))
# Store the model with the world column name as key
world_col = interval_mapping[as.character(interval_num)]
interval_models[[world_col]] = model
cat("Model successfully fit!\n")
print(summary(model))
}
# Now create predictions for each run in world_data
world_data = world_data %>%
mutate(
pred_W1_1 = predict(interval_models[["W1_1"]],
newdata = data.frame(DayNum = DayNum),
type = "response"),
pred_W1_2 = predict(interval_models[["W1_2"]],
newdata = data.frame(DayNum = DayNum),
type = "response"),
pred_W4_1 = predict(interval_models[["W4_1"]],
newdata = data.frame(DayNum = DayNum),
type = "response"),
pred_W4_2 = predict(interval_models[["W4_2"]],
newdata = data.frame(DayNum = DayNum),
type = "response"),
pred_W8_1 = predict(interval_models[["W8_1"]],
newdata = data.frame(DayNum = DayNum),
type = "response"),
pred_W8_2 = predict(interval_models[["W8_2"]],
newdata = data.frame(DayNum = DayNum),
type = "response"),
pred_W8_3 = predict(interval_models[["W8_3"]],
newdata = data.frame(DayNum = DayNum),
type = "response")
)
# Calculate overall WR probability as product of all interval probabilities
world_data = world_data %>%
mutate(
pred_WR_prob = pred_W1_1 * pred_W1_2 * pred_W4_1 * pred_W4_2 *
pred_W8_1 * pred_W8_2 * pred_W8_3
)
# Now use this predicted WR probability in your final model
final_model = logistf(W8_4 ~ pred_WR_prob, data = world_data)
final_model_cloglog = glm(W8_4 ~ pred_WR_prob,
data = world_data,
family = binomial(link = "cloglog"))
summary(final_model)
summary(final_model_cloglog)
#should make final pred_WR remain deterministic based on predicted probabilities, because pred_WR_prob isn't stat significant
# Check the predictions
world_data %>%
dplyr::select(DayNum, starts_with("pred_"), W8_4)
# 1. Check sample sizes
for (interval_num in 1:7) {
interval_subset = interval_data %>% filter(Interval == interval_num)
cat(sprintf("Interval %d: N = %d, Success Rate = %.3f\n",
interval_num, nrow(interval_subset), mean(interval_subset$Success)))
}
# 2. Check if non-significant coefficients are close to significance
# W4_1 (p=0.061) is borderline - with more data might become significant
# 3. Look at confidence intervals
for (interval_name in names(interval_models)) {
model = interval_models[[interval_name]]
ci = confint(model)
cat(sprintf("\n%s: Day coefficient 95%% CI: [%.4f, %.4f]\n",
interval_name, ci[2,1], ci[2,2]))
}
summary(interval_models$W1_1)
summary(interval_models$W1_2)
summary(interval_models$W4_1)
#Some issues with 4_1
summary(interval_models$W4_2)
summary(interval_models$W8_1)
#Some issues with 8_1
summary(interval_models$W8_2)
#Some issues with 8_2
summary(interval_models$W8_3)
#Some issues with 8_3
#Attempting same models with a logistf has the same issue with the models
# Get the exact coefficient and predicted probabilities
coef(interval_models[["W4_1"]])
# Calculate actual change over 21 days
pred_change <- predict(interval_models[["W4_1"]],
newdata = data.frame(DayNum = 21),
type = "response") -
predict(interval_models[["W4_1"]],
newdata = data.frame(DayNum = 1),
type = "response")
cat("Absolute change in success probability:", pred_change, "\n")
cat("As percentage points:", pred_change * 100, "\n")
pR2(interval_models$W1_1)
library(pscl)
pR2(interval_models$W1_1)
round(pR2(interval_models$W1_1),3)
null_dev = best_model$null.deviance
resid_dev = best_model$deviance
pseudo_r2 = 1 - (resid_dev / null_dev)
cat("\nMcFadden's Pseudo R-squared:", pseudo_r2, "\n")
cat("Interpretation: 0.2-0.4 = excellent fit\n")
hl_test = hoslem.test(interval_data$Success, fitted(best_model), g = 10)
print(hl_test)
cat("Hosmer-Lemeshow: p >0.05 indicates good fit\n")
geom_bar(stat = "identity", fill = "steelblue", alpha = 0.7) +
geom_hline(yintercept = 4/nrow(interval_data), color = "red",
linetype = "dashed", linewidth = 1) +
labs(title = "Cook's Distance - Influential Observations",
subtitle = "Points above red line may be influential",
x = "Observation Index",
y = "Cook's Distance") +
theme_minimal() +
theme(plot.title = element_text(hjust = 0.5, face = "bold"))
# Analyze best_model fit
# 3. Pearson Chi-Square Test
pearson_resid = residuals(best_model, type = "pearson")
pearson_chisq = sum(pearson_resid^2)
pearson_pval = 1 - pchisq(pearson_chisq, best_model$df.residual)
cat("\nPearson Chi-Square Test:\n")
cat("Chi-Square:", pearson_chisq, "\n")
cat("P-value:", pearson_pval, "\n")
# 4. Hosmer-Lemeshow Test
library(ResourceSelection)
hl_test = hoslem.test(interval_data$Success, fitted(best_model), g = 10)
print(hl_test)
cat("Hosmer-Lemeshow: p >0.05 indicates good fit\n")
# 5. McFadden's Pseudo R-squared
null_dev = best_model$null.deviance
resid_dev = best_model$deviance
pseudo_r2 = 1 - (resid_dev / null_dev)
cat("\nMcFadden's Pseudo R-squared:", pseudo_r2, "\n")
cat("Interpretation: 0.2-0.4 = excellent fit\n")
# 6. Calculate VIF for multicollinearity (if applicable)
cat("\nVariance Inflation Factors:\n")
vif_values = vif(best_model)
print(vif_values)
cat("VIF < 10 indicates no serious multicollinearity\n")
# 8. Influential Points
interval_data$cooks_d = cooks.distance(best_model)
# Graph 5: Cook's Distance
ggplot(interval_data, aes(x = 1:nrow(interval_data), y = cooks_d)) +
geom_bar(stat = "identity", fill = "steelblue", alpha = 0.7) +
geom_hline(yintercept = 4/nrow(interval_data), color = "red",
linetype = "dashed", linewidth = 1) +
labs(title = "Cook's Distance - Influential Observations",
subtitle = "Points above red line may be influential",
x = "Observation Index",
y = "Cook's Distance") +
theme_minimal() +
theme(plot.title = element_text(hjust = 0.5, face = "bold"))
# 9. Summary Statistics
cat("\n=== MODEL FIT SUMMARY ===\n")
cat("AIC:", AIC(best_model), "\n")
cat("BIC:", BIC(best_model), "\n")
cat("Log-Likelihood:", logLik(best_model), "\n")
cat("Pseudo R-squared:", pseudo_r2, "\n")
summary(interval_models$W1_1)
summary(best_model)
#Now that we've shown that there is improvement
# Model improvement over time on interval completion
cloglog_time = glm(Success ~ DayNum + factor(Interval),
data = interval_data,
family = binomial(link = "cloglog"))
summary(cloglog_time)
summary(best_model)
library(tidyverse)
library(ggplot2)
# Assuming you have interval_data loaded
# If not, load it first:
# interval_data <- read.csv("FINAL DATA.csv")
# Convert Day to numeric
interval_data <- interval_data %>%
mutate(DayNum = as.numeric(gsub('Day_', '', Day)))
# Calculate daily success rate for Interval 1 only
interval_1_daily <- interval_data %>%
filter(Interval == 1) %>%
group_by(DayNum) %>%
summarise(
success_rate = mean(Success),
n_attempts = n(),
.groups = 'drop'
)
# Create the plot
p <- ggplot(interval_1_daily, aes(x = DayNum, y = success_rate)) +
# Add points sized by number of attempts
geom_point(aes(size = n_attempts), color = "#2980b9", alpha = 0.6) +
# Add trend line with confidence interval
geom_smooth(method = "lm", se = TRUE, color = "#e74c3c",
fill = "#e74c3c", alpha = 0.2, linewidth = 1.2) +
# Add horizontal reference lines for Day 1 and Day 21
geom_hline(yintercept = 0.631, linetype = "dashed",
color = "gray40", linewidth = 0.8) +
geom_hline(yintercept = 0.686, linetype = "dashed",
color = "gray40", linewidth = 0.8) +
# Annotate Day 1 value
annotate("text", x = 2, y = 0.631,
label = "Day 1: 63.1%",
hjust = 0, vjust = -0.5, size = 3.5, fontface = "bold") +
# Annotate Day 21 value
annotate("text", x = 19, y = 0.686,
label = "Day 21: 68.6%",
hjust = 1, vjust = -0.5, size = 3.5, fontface = "bold") +
# Labels and formatting
labs(
title = "Interval 1 Success Rate Improvement Over Time",
subtitle = "+5.5 percentage points over 21 days (8.7% relative increase)",
x = "Training Day",
y = "Success Rate",
size = "Attempts"
) +
# Format y-axis as percentage
scale_y_continuous(labels = scales::percent_format(accuracy = 1),
limits = c(0.55, 0.75),
breaks = seq(0.55, 0.75, by = 0.05)) +
# Format x-axis
scale_x_continuous(breaks = seq(1, 21, by = 2)) +
# Adjust point size scale
scale_size_continuous(range = c(3, 8), guide = "none") +
# Clean theme
theme_minimal(base_size = 12) +
theme(
plot.title = element_text(face = "bold", hjust = 0.5, size = 14),
plot.subtitle = element_text(hjust = 0.5, size = 11, color = "gray30"),
panel.grid.minor = element_blank(),
axis.title = element_text(face = "bold", size = 11),
legend.position = "none"
)
# Display the plot
print(p)
# Save the plot
ggsave("interval_1_improvement.png", plot = p,
width = 8, height = 5, dpi = 300, bg = "white")
cat("✓ Saved interval_1_improvement.png\n")
# Calculate daily success rates for multiple intervals
selected_intervals <- interval_data %>%
filter(Interval %in% c(1, 2, 4, 7)) %>%  # Select representative intervals
group_by(DayNum, Interval) %>%
summarise(
success_rate = mean(Success),
n_attempts = n(),
.groups = 'drop'
)
# Create comparison plot
p2 <- ggplot(selected_intervals, aes(x = DayNum, y = success_rate,
color = factor(Interval))) +
geom_point(alpha = 0.5, size = 2) +
geom_smooth(method = "lm", se = TRUE, alpha = 0.15, linewidth = 1.2) +
# Highlight Interval 1
geom_smooth(data = selected_intervals %>% filter(Interval == 1),
aes(x = DayNum, y = success_rate),
method = "lm", se = FALSE,
color = "#e74c3c", linewidth = 1.8, linetype = "solid") +
labs(
title = "Learning Curves by Interval Difficulty",
subtitle = "Interval 1 (baseline) shown with thick red line",
x = "Training Day",
y = "Success Rate",
color = "Interval"
) +
scale_y_continuous(labels = scales::percent_format(accuracy = 1),
limits = c(0, 1)) +
scale_x_continuous(breaks = seq(1, 21, by = 3)) +
scale_color_manual(
values = c("1" = "#e74c3c", "2" = "#3498db",
"4" = "#f39c12", "7" = "#2ecc71"),
labels = c("1" = "Interval 1 (63%)",
"2" = "Interval 2 (74%)",
"4" = "Interval 4 (16%)",
"7" = "Interval 7 (88%)")
) +
theme_minimal(base_size = 12) +
theme(
plot.title = element_text(face = "bold", hjust = 0.5, size = 14),
plot.subtitle = element_text(hjust = 0.5, size = 11),
panel.grid.minor = element_blank(),
legend.position = "right"
)
print(p2)
ggsave("learning_curves_comparison.png", plot = p2,
width = 9, height = 5, dpi = 300, bg = "white")
cat("✓ Saved learning_curves_comparison.png\n")
