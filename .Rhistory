knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE,
fig.width = 6, fig.height = 4)
library(tidyverse)
library(knitr)
library(readxl)
library(MASS)
library(dplyr)
library(car)
library(broom)
library(GGally)
#Read in some of the the data for testing
read.csv("World 1-1 Data.csv")
#Read in some of the the data for testing
World_one-one = read.csv("World 1-1 Data.csv")
#Read in some of the the data for testing
World_one_one = read.csv("World 1-1 Data.csv")
World_one_one
mean(World_one_one)
mean(World_one_one[-1])
mean(World_one_one)
glimpse(World_one_one)
World_one_one[-1]
glimpse(World_one_one[-1])
mean(World_one_one[1,])
glimpse(World_one_one[1,])
glimpse(World_one_one[-1,])
mean(World_one_one[-1,])
sum(World_one_one[-1,])
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE,
fig.width = 6, fig.height = 4)
library(tidyverse)
library(knitr)
library(readxl)
library(MASS)
library(dplyr)
library(car)
library(broom)
library(GGally)
# Load required libraries
library(faraway)
library(faraway)
# Create a time index since we don't have other predictors
World_one_one$time = 1:nrow(World_one_one)
#Read in some of the the data for testing
World_one_one = read.csv("World 1-1 Data.csv")
sum(World_one_one[-1,]) #Data checks out
# Create a time index since we don't have other predictors
World_one_one$time = 1:nrow(World_one_one)
World_one_one
plot(World_one_one)
#Read in some of the the data for testing
World_one_one = read.csv("World 1-1 Data.csv")
sum(World_one_one[-1,]) #Data checks out
# Create a time index since we don't have other predictors
World_one_one$time = 1:nrow(World_one_one)
# Fit a Poisson GLM with time as predictor
pois_glm = glm(value ~ time, data = World_one_one, family = poisson)
# View summary
summary(pois_glm)
# Test against null model (intercept only)
null_model = glm(value ~ 1, data = World_one_one, family = poisson)
chi_stat = deviance(null_model) - deviance(pois_glm)
df_diff = df.residual(null_model) - df.residual(pois_glm)
p_value = 1 - pchisq(chi_stat, df_diff)
cat("Chi-square test against null model:\n")
cat("Chi-square statistic:", chi_stat, "\n")
cat("df:", df_diff, "\n")
cat("p-value:", p_value, "\n\n")
# Goodness of fit test
gof_p_value = 1 - pchisq(deviance(pois_glm), df.residual(pois_glm))
cat("Goodness of fit test:\n")
cat("Deviance:", deviance(pois_glm), "\n")
cat("df:", df.residual(pois_glm), "\n")
cat("p-value:", gof_p_value, "\n\n")
# Check for overdispersion
dispersion_deviance = deviance(pois_glm) / df.residual(pois_glm)
dispersion_pearson = sum(residuals(pois_glm, type = "pearson")^2) / df.residual(pois_glm)
cat("Dispersion parameter estimates:\n")
cat("Based on deviance:", dispersion_deviance, "\n")
cat("Based on Pearson residuals:", dispersion_pearson, "\n\n")
# Halfnorm plot of residuals
halfnorm(residuals(pois_glm))
install.packages(faraway)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE,
fig.width = 6, fig.height = 4)
library(tidyverse)
library(knitr)
library(readxl)
library(MASS)
library(dplyr)
library(car)
library(broom)
library(GGally)
#Read in some of the the data for testing
World_one_one = read.csv("World 1-1 Data.csv")
sum(World_one_one[-1,]) #Data checks out
# Create a time index since we don't have other predictors
World_one_one$time = 1:nrow(World_one_one)
# Fit a Poisson GLM with time as predictor
pois_glm = glm(value ~ time, data = World_one_one, family = poisson)
# View summary
summary(pois_glm)
# Test against null model (intercept only)
null_model = glm(value ~ 1, data = World_one_one, family = poisson)
chi_stat = deviance(null_model) - deviance(pois_glm)
df_diff = df.residual(null_model) - df.residual(pois_glm)
p_value = 1 - pchisq(chi_stat, df_diff)
cat("Chi-square test against null model:\n")
cat("Chi-square statistic:", chi_stat, "\n")
cat("df:", df_diff, "\n")
cat("p-value:", p_value, "\n\n")
# Goodness of fit test
gof_p_value = 1 - pchisq(deviance(pois_glm), df.residual(pois_glm))
cat("Goodness of fit test:\n")
cat("Deviance:", deviance(pois_glm), "\n")
cat("df:", df.residual(pois_glm), "\n")
cat("p-value:", gof_p_value, "\n\n")
# Check for overdispersion
dispersion_deviance = deviance(pois_glm) / df.residual(pois_glm)
dispersion_pearson = sum(residuals(pois_glm, type = "pearson")^2) / df.residual(pois_glm)
cat("Dispersion parameter estimates:\n")
cat("Based on deviance:", dispersion_deviance, "\n")
cat("Based on Pearson residuals:", dispersion_pearson, "\n\n")
# Plot fitted vs observed
plot(log(fitted(pois_glm)), log((World_one_one$value - fitted(pois_glm))^2),
xlab = expression(hat(lambda)),
ylab = expression((y - hat(lambda))^2),
main = "Variance vs Mean Plot")
abline(0, 1)
#Read in some of the the data for testing
World_one_one = read.csv("World 1-1 Data.csv")
sum(World_one_one[-1,]) #Data checks out
# Create a time index since we don't have other predictors
World_one_one$time = 1:nrow(World_one_one)
# Fit a Poisson GLM with time as predictor
pois_glm = glm(value ~ time, data = World_one_one, family = poisson)
# View summary
summary(pois_glm)
# Test against null model (intercept only)
null_model = glm(value ~ 1, data = World_one_one, family = poisson)
chi_stat = deviance(null_model) - deviance(pois_glm)
df_diff = df.residual(null_model) - df.residual(pois_glm)
p_value = 1 - pchisq(chi_stat, df_diff)
cat("Chi-square test against null model:\n")
cat("Chi-square statistic:", chi_stat, "\n")
cat("df:", df_diff, "\n")
cat("p-value:", p_value, "\n\n")
# Goodness of fit test
gof_p_value = 1 - pchisq(deviance(pois_glm), df.residual(pois_glm))
cat("Goodness of fit test:\n")
cat("Deviance:", deviance(pois_glm), "\n")
cat("df:", df.residual(pois_glm), "\n")
cat("p-value:", gof_p_value, "\n\n")
# Check for overdispersion
dispersion_deviance = deviance(pois_glm) / df.residual(pois_glm)
dispersion_pearson = sum(residuals(pois_glm, type = "pearson")^2) / df.residual(pois_glm)
cat("Dispersion parameter estimates:\n")
cat("Based on deviance:", dispersion_deviance, "\n")
cat("Based on Pearson residuals:", dispersion_pearson, "\n\n")
# Plot fitted vs observed
plot(log(fitted(pois_glm)), log((World_one_one$value - fitted(pois_glm))^2),
xlab = expression(hat(lambda)),
ylab = expression((y - hat(lambda))^2),
main = "Variance vs Mean Plot")
abline(0, 1)
#Read in some of the the data for testing
World_one_one = read.csv("World 1-1 Data.csv")
sum(World_one_one[-1,]) #Data checks out
# Create a time index since we don't have other predictors
World_one_one$time = 1:nrow(World_one_one)
# Fit a Poisson GLM with time as predictor
pois_glm = glm(value ~ time, data = World_one_one, family = poisson)
# View summary
summary(pois_glm)
# Test against null model (intercept only)
null_model = glm(value ~ 1, data = World_one_one, family = poisson)
chi_stat = deviance(null_model) - deviance(pois_glm)
df_diff = df.residual(null_model) - df.residual(pois_glm)
p_value = 1 - pchisq(chi_stat, df_diff)
# Goodness of fit test
gof_p_value = 1 - pchisq(deviance(pois_glm), df.residual(pois_glm))
# Check for overdispersion
dispersion_deviance = deviance(pois_glm) / df.residual(pois_glm)
dispersion_pearson = sum(residuals(pois_glm, type = "pearson")^2) / df.residual(pois_glm)
# Plot fitted vs observed
plot(log(fitted(pois_glm)), log((World_one_one$value - fitted(pois_glm))^2),
xlab = expression(hat(lambda)),
ylab = expression((y - hat(lambda))^2),
main = "Variance vs Mean Plot")
abline(0, 1)
gof_p_value
anova(null_model, pois_glm)
anova(pos_glm, null_model)
anova(pois_glm, null_model)
dispersion_deviance = deviance(pois_glm) / df.residual(pois_glm)
dispersion_pearson = sum(residuals(pois_glm, type = "pearson")^2) / df.residual(pois_glm)
cat("Dispersion parameter estimates:\n")
cat("Based on deviance:", dispersion_deviance, "\n")
cat("Based on Pearson residuals:", dispersion_pearson, "\n\n")
# Plot fitted vs observed
plot(log(fitted(pois_glm)), log((World_one_one$value - fitted(pois_glm))^2),
xlab = expression(hat(lambda)),
ylab = expression((y - hat(lambda))^2),
main = "Variance vs Mean Plot")
abline(0, 1)
library(tidyverse)
# Data import and cleaning
wr <- read.csv("~/Downloads/history.csv")
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE,
fig.width = 6, fig.height = 4)
library(tidyverse)
library(knitr)
library(readxl)
library(MASS)
library(dplyr)
library(car)
library(broom)
library(GGally)
#logistic regression with ZIP is best bet, doing research now
zib_0 <- glmmTMB(
W8_4 ~ 1,        # count (binomial) part: intercept only
ziformula = ~ 1, # zero-inflation part: intercept only
family = binomial,
data = data
)
library(glmmTMB)
#logistic regression with ZIP is best bet, doing research now
zib_0 <- glmmTMB(
W8_4 ~ 1,        # count (binomial) part: intercept only
ziformula = ~ 1, # zero-inflation part: intercept only
family = binomial,
data = data
)
zib_0 <- glmmTMB(
W8_4 ~ 1,        # count (binomial) part: intercept only
ziformula = ~ 1, # zero-inflation part: intercept only
family = binomial,
data = data
)
install.packages("glmnTMB")
library(glmmTMB)
#logistic regression with ZIP is best bet, doing research now
zib_0 <- glmmTMB(
W8_4 ~ 1,        # count (binomial) part: intercept only
ziformula = ~ 1, # zero-inflation part: intercept only
family = binomial,
data = data
)
#logistic regression with ZIP is best bet, doing research now
df = data
df = as.data.frame(df)
df
#logistic regression with ZIP is best bet, doing research now
df = as.data.frame(data)
data
World_one_one = read.csv("World 1-1 Data.csv")
World_one_two = read.csv("World 1-2 Data.csv")
World_four_one = read.csv("World 4-1 Data.csv")
World_four_two = read.csv("World 4-2 Data.csv")
World_eight_one = read.csv("World 8-1 Data.csv")
World_eight_two = read.csv("World 8-2 Data.csv")
World_eight_three = read.csv("World 8-3 Data.csv")
World_eight_four = read.csv("World 8-4 Data.csv")
data = cbind(
World_one_one,
World_one_two,
World_four_one,
World_four_two,
World_eight_one,
World_eight_two,
World_eight_three,
World_eight_four
)
names(data) = c("W1_1", "W1_2", "W4_1", "W4_2", "W8_1", "W8_2", "W8_3", "W8_4")
glimpse(data)
data
#logistic regression with ZIP is best bet, doing research now
zib_0 <- glmmTMB(
W8_4 ~ 1,        # count (binomial) part: intercept only
ziformula = ~ 1, # zero-inflation part: intercept only
family = binomial,
data = data
)
summary(zib_0)
#logistic regression with ZIP is best bet, doing research now
zib_0 <- glmmTMB(
W8_4 ~ 1,        # count (binomial) part: intercept only
ziformula = ~ 1, # zero-inflation part: intercept only
family = binomial,
data = data
)
install.packages("logistf")
install.packages("logistf")
library(logistf)
#Trying something else, something simpler
# Score = number of earlier worlds cleared in that attempt
mario_data$score_prev <- mario_data$W1_1 + mario_data$W1_2 +
mario_data$W4_1 + mario_data$W4_2 +
mario_data$W8_1 + mario_data$W8_2 +
mario_data$W8_3
World_one_one = read.csv("World 1-1 Data.csv")
World_one_two = read.csv("World 1-2 Data.csv")
World_four_one = read.csv("World 4-1 Data.csv")
World_four_two = read.csv("World 4-2 Data.csv")
World_eight_one = read.csv("World 8-1 Data.csv")
World_eight_two = read.csv("World 8-2 Data.csv")
World_eight_three = read.csv("World 8-3 Data.csv")
World_eight_four = read.csv("World 8-4 Data.csv")
data = cbind(
World_one_one,
World_one_two,
World_four_one,
World_four_two,
World_eight_one,
World_eight_two,
World_eight_three,
World_eight_four
)
names(data) = c("W1_1", "W1_2", "W4_1", "W4_2", "W8_1", "W8_2", "W8_3", "W8_4")
glimpse(data)
#Trying something else, something simpler
# Score = number of earlier worlds cleared in that attempt
data$score_prev <- data$W1_1 + data$W1_2 +
data$W4_1 + data$W4_2 +
data$W8_1 + data$W8_2 +
data$W8_3
table(data$score_prev)
table(data$W8_4)
# Firth logistic regression: predictive model for 8-4 success
fit_firth <- logistf(
W8_4 ~ score_prev,
data = data
)
summary(fit_firth)
# Predicted probability for each attempt
data$pred_p_8_4 <- predict(fit_firth, type = "response")
head(data$pred_p_8_4)
#Trying something else, something simpler
# Score = number of earlier worlds cleared in that attempt
data$score_prev <- data$W1_1 + data$W1_2 +
data$W4_1 + data$W4_2 +
data$W8_1 + data$W8_2 +
data$W8_3
table(data$score_prev)
table(data$W8_4)
# Firth logistic regression: predictive model for 8-4 success
fit_firth <- logistf(
W8_4 ~ score_prev,
data = data
)
summary(fit_firth)
# Predicted probability for each attempt
data$pred_p_8_4 <- predict(fit_firth, type = "response")
head(data$pred_p_8_4)
# Predicted probability for each attempt
data$pred_p_8_4 <- predict(fit_firth, type = "response")
head(data$pred_p_8_4)
# Average predicted probability across all runs
mean(data$pred_p_8_4)
# Predicted probability for a "perfect so far" run (score_prev = 7)
new_run <- data.frame(score_prev = 7)
predict(fit_firth, newdata = new_run, type = "response")
#Other model if logistf is not acceptable
logit_simple <- glm(
W8_4 ~ score_prev,
data   = data,
family = binomial
)
summary(logit_simple)
#logistic regression with ZIP is best bet, doing research now
zib_0 = glmmTMB(
W8_4 ~ 1,        # count (binomial) part: intercept only
ziformula = ~ 1, # zero-inflation part: intercept only
family = binomial(link = logit),
data = data
)
#Final model can output probability of WR on next attempt given current performance...
#This can be used to simulate the Probability of a WR within N attempts 1 - (1 - p_hat)^N
#bayesian model building
stage_stats <- tibble()
for (k in seq_along(stages)) {
stage_name <- stages[k]
# "Reached" this stage = succeeded on all previous stages
if (k == 1) {
reached <- rep(TRUE, nrow(data))
} else {
prev_stages <- stages[1:(k-1)]
reached <- apply(data[, prev_stages, drop = FALSE] == 1, 1, all)
}
n_k <- sum(reached)                              # number of attempts that reached this stage
y_k <- sum(data[[stage_name]][reached] == 1)     # successes at this stage
stage_stats <- bind_rows(
stage_stats,
tibble(
stage     = stage_name,
index     = k,
reached_n = n_k,
success_y = y_k,
p_hat     = ifelse(n_k > 0, y_k / n_k, NA_real_)
)
)
}
#Final model can output probability of WR on next attempt given current performance...
#This can be used to simulate the Probability of a WR within N attempts 1 - (1 - p_hat)^N
#bayesian model building
stages <- c("W1_1", "W1_2", "W4_1", "W4_2", "W8_1", "W8_2", "W8_3", "W8_4")
stage_stats <- tibble()
for (k in seq_along(stages)) {
stage_name <- stages[k]
# "Reached" this stage = succeeded on all previous stages
if (k == 1) {
reached <- rep(TRUE, nrow(data))
} else {
prev_stages <- stages[1:(k-1)]
reached <- apply(data[, prev_stages, drop = FALSE] == 1, 1, all)
}
n_k <- sum(reached)                              # number of attempts that reached this stage
y_k <- sum(data[[stage_name]][reached] == 1)     # successes at this stage
stage_stats <- bind_rows(
stage_stats,
tibble(
stage     = stage_name,
index     = k,
reached_n = n_k,
success_y = y_k,
p_hat     = ifelse(n_k > 0, y_k / n_k, NA_real_)
)
)
}
stage_stats
stage_stats %>%
ggplot(aes(x = reorder(stage, index), y = p_hat)) +
geom_col() +
ylim(0, 1) +
labs(
title = "Empirical Conditional Success Probability by Stage",
x = "Stage",
y = "Estimated P(success | reached stage)"
) +
theme_bw()
