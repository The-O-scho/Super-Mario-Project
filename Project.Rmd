---
title: "Project"
author: "Theo and Thomas"
date: "October 2025"
output:
  pdf_document:
    toc: false
    number_sections: false
fontsize: 11pt
geometry: margin=1in
urlcolor: blue
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE,
                      fig.width = 6, fig.height = 4)
library(tidyverse)
library(knitr)
library(readxl)
library(MASS)
library(dplyr)
library(car)
library(broom)
library(GGally)
library(glmmTMB)
library(logistf)
```

```{r}
World_one_one = read.csv("World 1-1 Data.csv")
World_one_two = read.csv("World 1-2 Data.csv")
World_four_one = read.csv("World 4-1 Data.csv")
World_four_two = read.csv("World 4-2 Data.csv")
World_eight_one = read.csv("World 8-1 Data.csv")
World_eight_two = read.csv("World 8-2 Data.csv")
World_eight_three = read.csv("World 8-3 Data.csv")
World_eight_four = read.csv("World 8-4 Data.csv")

data = cbind(
  World_one_one,
  World_one_two,
  World_four_one,
  World_four_two,
  World_eight_one,
  World_eight_two,
  World_eight_three,
  World_eight_four
)
names(data) = c("W1_1", "W1_2", "W4_1", "W4_2", "W8_1", "W8_2", "W8_3", "W8_4")
glimpse(data)
```

```{r}
#Over ride data with new ordered data for testing
data = read.csv("Nifski Ordered.csv")
glimpse(data)
```



```{r}
# Build Poisson regression model:
pois_8_4 = glm(W8_4 ~ W1_1 + W1_2 + W4_1 + W4_2 + W8_1 + W8_2 + W8_3, data   = data, family = poisson)

# Look at basic model output (no interpretation here)
summary(pois_8_4)

# (Optional) compare to null model and basic GOF checks, following class notes
null_pois_8_4 = glm(W8_4 ~ 1, data = data, family = poisson)

# Likelihood ratio test vs null
anova(null_pois_8_4, pois_8_4, test = "Chisq")

#Poisson doesn't look very good, binomial is next
```

```{r}
# Fit logistic regression model
logit_8_4 = glm(W8_4 ~ W1_1 + W1_2 + W4_1 + W4_2 + W8_1 + W8_2 + W8_3, data   = data, family = binomial(link = "logit"))

summary(logit_8_4)

# Null (intercept-only) model
null_logit_8_4 = glm(W8_4 ~ 1, data = data, family = binomial(link = "logit"))

anova(null_logit_8_4, logit_8_4, test = "Chisq")

#binomial doesnt look good either
```

```{r}
#Negative binomial because its success into success into success that makes it to the last stage
nb_model = glm.nb(W8_4 ~ W1_1 + W1_2 + W4_1 + W4_2 + W8_1 + W8_2 + W8_3, data = data)

summary(nb_model)

```


```{r}
#logistic regression with ZIP is best bet, doing research now
zib_0 = glmmTMB(
  W8_4 ~ 1,        # count (binomial) part: intercept only
  ziformula = ~ 1, # zero-inflation part: intercept only
  family = binomial(link = logit),
  data = data
)

summary(zib_0)

zib_full = glmmTMB(
  W8_4 ~ W1_1 + W1_2 + W4_1 + W4_2 + W8_1 + W8_2 + W8_3,        # count (binomial) part: intercept only
  ziformula = ~ W1_1 + W1_2 + W4_1 + W4_2 + W8_1 + W8_2 + W8_3, # zero-inflation part: intercept only
  family = binomial(link = logit),
  data = data
)
summary(zib_full)
#no warning but still NAN p values
``` 

```{r}
firth_8_4 = logistf(W8_4 ~ W1_1 + W1_2 + W4_1 + W4_2 + W8_1 + W8_2 + W8_3, 
                     data = data)

summary(firth_8_4)



# Create composite features
data = data %>%
  mutate(
    # Total successes in early levels (W1)
    W1_total = W1_1 + W1_2,
    
    # Total successes in mid levels (W4)
    W4_total = W4_1 + W4_2,
    
    # Total successes in late levels (W8, excluding outcome)
    W8_prior = W8_1 + W8_2 + W8_3,
    
    # Overall success rate up to W8_3
    success_rate = (W1_1 + W1_2 + W4_1 + W4_2 + W8_1 + W8_2 + W8_3) / 7
  )

# Simpler model with composite features
firth_composite = logistf(W8_4 ~ W1_total + W4_total + W8_prior, data = data)
summary(firth_composite) #only W_8 prior matters maybe build up just previous w_8??? idk

# Or even simpler - just overall success rate
firth_simple = logistf(W8_4 ~ success_rate, data = data)
summary(firth_simple) #finally a significant p-val in just using success rate
```
Block for testing firth_simple
Actually a good fit, decent predictions, Nifski has around a 21% completion rate on average for all previous levels. dataset updated with predictions from this.

```{r}
library(logistf)
library(ggplot2)
library(dplyr)

# Your model
firth_simple = logistf(W8_4 ~ success_rate, data = data)
summary(firth_simple)

# 1. Generate predictions for your existing data
data$predicted_prob = predict(firth_simple, type = "response")

# 2. Look at predictions for different success rates
# Create a sequence of success rates from 0 to 1
new_data = data.frame(success_rate = seq(0, 1, by = 0.1))
new_data$predicted_prob = predict(firth_simple, newdata = new_data, type = "response")

print("Predicted probabilities of breaking world record:")
print(new_data)

# 3. Summary statistics of predictions
cat("\nPrediction Summary:\n")
cat("Min predicted probability:", min(data$predicted_prob), "\n")
cat("Max predicted probability:", max(data$predicted_prob), "\n")
cat("Mean predicted probability:", mean(data$predicted_prob), "\n")
cat("Actual world record rate:", mean(data$W8_4), "\n")

# 4. DIAGNOSTIC PLOT 1: Predicted probabilities vs actual outcomes
ggplot(data, aes(x = predicted_prob, fill = as.factor(W8_4))) +
  geom_histogram(position = "identity", alpha = 0.6, bins = 30) +
  labs(title = "Distribution of Predicted Probabilities",
       x = "Predicted Probability of World Record",
       y = "Count",
       fill = "Actual WR") +
  scale_fill_manual(values = c("0" = "red", "1" = "green"),
                    labels = c("No WR", "WR")) +
  theme_minimal()



# 6. DIAGNOSTIC PLOT 3: Success rate vs probability curve
ggplot(data, aes(x = success_rate, y = predicted_prob)) +
  geom_point(aes(color = as.factor(W8_4)), alpha = 0.5) +
  geom_smooth(method = "loess", se = TRUE, color = "blue") +
  labs(title = "Success Rate vs Predicted Probability",
       x = "Success Rate (prior levels)",
       y = "Predicted Probability of World Record",
       color = "Actual WR") +
  scale_color_manual(values = c("0" = "red", "1" = "green"),
                     labels = c("No WR", "WR")) +
  theme_minimal()

# 7. ROC CURVE and AUC (measure of discrimination)
library(pROC)
roc_obj = roc(data$W8_4, data$predicted_prob)
auc_value = auc(roc_obj)

plot(roc_obj, main = paste("ROC Curve (AUC =", round(auc_value, 3), ")"))
cat("\nAUC (Area Under Curve):", auc_value, "\n")
cat("Interpretation: AUC > 0.7 = acceptable, > 0.8 = excellent\n")


# 9. Hosmer-Lemeshow test (goodness of fit)
library(ResourceSelection)
hl_test = hoslem.test(data$W8_4, data$predicted_prob, g = 10)
print(hl_test)
cat("Hosmer-Lemeshow test: p >0.05 indicates good fit\n")

# 10. Example predictions for specific scenarios
example_scenarios = data.frame(
  scenario = c("Beginner", "Intermediate", "Advanced", "Expert"),
  success_rate = c(0.2, 0.5, 0.8, 0.95)
)

example_scenarios$WR_probability = predict(firth_simple, 
                                            newdata = example_scenarios, 
                                            type = "response")

cat("\n Example Predictions \n")
print(example_scenarios)


target_row = data[
  data$W1_1 == 1 &
  data$W1_2 == 1 &
  data$W4_1 == 1 &
  data$W4_2 == 1 &
  data$W8_1 == 1 &
  data$W8_2 == 1 &
  data$W8_3 == 1,
]

```



Bayesian Start Here


```{r}
#Final model can output probability of WR on next attempt given current performance...
#This can be used to simulate the Probability of a WR within N attempts 1 - (1 - p_hat)^N
#bayesian model building
stages = c("W1_1", "W1_2", "W4_1", "W4_2", "W8_1", "W8_2", "W8_3", "W8_4")
stage_stats = tibble()

for (k in seq_along(stages)) {
  stage_name = stages[k]
  
  # "Reached" this stage = succeeded on all previous stages
  if (k == 1) {
    reached = rep(TRUE, nrow(data))
  } else {
    prev_stages = stages[1:(k-1)]
    reached = apply(data[, prev_stages, drop = FALSE] == 1, 1, all)
  }
  
  n_k = sum(reached)                              # number of attempts that reached this stage
  y_k = sum(data[[stage_name]][reached] == 1)     # successes at this stage
  
  stage_stats = bind_rows(
    stage_stats,
    tibble(
      stage     = stage_name,
      index     = k,
      reached_n = n_k,
      success_y = y_k,
      p_hat     = ifelse(n_k > 0, y_k / n_k, NA_real_)
    )
  )
}

stage_stats

```

```{r}
stage_stats %>%
  ggplot(aes(x = reorder(stage, index), y = p_hat)) +
  geom_col() +
  ylim(0, 1) +
  labs(
    title = "Empirical Conditional Success Probability by Stage",
    x = "Stage",
    y = "Estimated P(success | reached stage)"
  ) +
  theme_bw()
```

```{r}
alpha0 = 1
beta0  = 1

stage_stats = stage_stats %>%
  mutate(
    alpha_post = alpha0 + success_y,
    beta_post  = beta0 + reached_n - success_y,
    mean_post  = alpha_post / (alpha_post + beta_post),
    lower95    = qbeta(0.025, alpha_post, beta_post),
    upper95    = qbeta(0.975, alpha_post, beta_post)
  )

stage_stats

```

```{r}

stage_stats %>%
  ggplot(aes(x = reorder(stage, index), y = mean_post)) +
  geom_point(size = 3) +
  geom_errorbar(aes(ymin = lower95, ymax = upper95), width = 0.2) +
  ylim(0, 1) +
  labs(
    title = "Posterior Success Probability by Stage (Beta-Binomial)",
    x = "Stage",
    y = "Posterior mean P(success | reached stage)"
  ) +
  theme_bw()
```

```{r}
set.seed(123)

n_sims = 100000

# Draw samples from each stage's posterior
p_draws_list = lapply(seq_len(nrow(stage_stats)), function(i) {
  a = stage_stats$alpha_post[i]
  b = stage_stats$beta_post[i]
  rbeta(n_sims, a, b)
})

# Convert list to matrix: rows = sims, cols = stages
p_draws_mat = do.call(cbind, p_draws_list)

# Product across stages for each simulation = WR probability in that simulation
wr_prob_draws = apply(p_draws_mat, 1, prod)

# Summaries
wr_summary = tibble(
  mean       = mean(wr_prob_draws),
  median     = median(wr_prob_draws),
  lower95    = quantile(wr_prob_draws, 0.025),
  upper95    = quantile(wr_prob_draws, 0.975)
)

wr_summary
```

```{r}
tibble(wr_prob = wr_prob_draws) %>%
  ggplot(aes(x = wr_prob)) +
  geom_histogram(bins = 50) +
  labs(
    title = "Posterior Distribution of WR Probability (Per Attempt)",
    x = "P(WR on a single attempt)",
    y = "Frequency"
  ) +
  theme_bw()
```

```{r}
tibble(log10_wr_prob = log10(wr_prob_draws)) %>%
  ggplot(aes(x = log10_wr_prob)) +
  geom_histogram(bins = 50) +
  labs(
    title = "Posterior Distribution of log10 WR Probability",
    x = "log10 P(WR per attempt)",
    y = "Frequency"
  ) +
  theme_bw()
```






