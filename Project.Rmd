---
title: "Project"
author: "Theo and Thomas"
date: "October 2025"
output:
  pdf_document:
    toc: false
    number_sections: false
fontsize: 11pt
geometry: margin=1in
urlcolor: blue
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE,
                      fig.width = 6, fig.height = 4)
library(tidyverse)
library(knitr)
library(readxl)
library(MASS)
library(dplyr)
library(car)
library(broom)
library(GGally)
library(glmmTMB)
library(logistf)
library(ggplot2)
library(ResourceSelection)
```

Interval world_data 
```{r}
interval_data = read.csv("FINAL DATA.csv")

interval_data   
```

Create world_data 
```{r}
#Read in world_data  (world_data  is ordered)
world_data   = read.csv("FINAL WORLD DATA.csv")

world_data 
```

<!-- Create time varied world_data  -->
<!-- ```{r} -->
<!-- # Create dayâ€“level improvement variable -->

<!-- day_summary = world_data  %>% -->
<!--   group_by(Day) %>% -->
<!--   summarise( -->
<!--     day_success_rate = mean(success_rate), -->
<!--     .groups = "drop" -->
<!--   ) %>% -->

<!--   mutate( -->
<!--     time_index = as.numeric(factor(Day)) -->
<!--   ) %>% -->
<!--   arrange(time_index) %>% -->

<!--   mutate( -->
<!--     day_improvement = day_success_rate - lag(day_success_rate), -->
<!--     day_cum_improvement = day_success_rate - first(day_success_rate) -->
<!--   ) -->


<!-- world_data  = world_data  %>% -->
<!--   left_join(day_summary, by = "Day") -->

<!-- world_data $day_improvement[is.na(world_data $day_improvement)] = 0 -->

<!-- world_data  -->

<!-- #Graph day_success_rate over time grouped by date to find IF there is improvement over time -->


<!-- ``` -->
Create model for improvement over time
```{r}
interval_data = interval_data   %>%
  mutate(DayNum = as.numeric(gsub('Day_', '', Day)))

world_data = world_data  %>%
  mutate(DayNum = as.numeric(gsub('Day_', '', Day)))

# Calculate success rate by day and interval
daily_interval_success = interval_data   %>%
  group_by(DayNum, Interval) %>%
  summarise(
    success_rate = mean(Success),
    n_attempts = n(),
    .groups = 'drop'
  )

# Calculate overall success rate by day (across all intervals)
daily_overall_success = interval_data   %>%
  group_by(DayNum) %>%
  summarise(
    overall_success_rate = mean(Success),
    total_attempts = n(),
    .groups = 'drop'
  )

# Calculate how far Nifski get on average each day
daily_progression = interval_data   %>%
  group_by(DayNum, Run) %>%
  summarise(
    max_interval_reached = max(Interval[Success == 1]),
    .groups = 'drop'
  ) %>%
  group_by(DayNum) %>%
  summarise(
    avg_max_interval = mean(max_interval_reached),
    median_max_interval = median(max_interval_reached),
    .groups = 'drop'
  )

interval_data
```

Graphs
```{r}
# Graph 1: Overall Success Rate Over Time (Enhanced with Legend)
ggplot(daily_overall_success, aes(x = DayNum, y = overall_success_rate)) +
  geom_point(aes(color = "Daily Success Rate"), size = 4, alpha = 0.7) +
  geom_smooth(aes(color = "Smoothed Trend"), 
              method = "loess", se = FALSE, linewidth = 1.5) +
  geom_smooth(aes(color = "Linear Trend"), 
              method = "lm", se = TRUE, linewidth = 1.2, alpha = 0.2) +
  scale_color_manual(name = "Legend",
                     values = c("Daily Success Rate" = "steelblue",
                               "Smoothed Trend" = "darkblue",
                               "Linear Trend" = "red")) +
  scale_y_continuous(labels = scales::percent_format(accuracy = 1), 
                     limits = c(0.50, 0.70)) +
  scale_x_continuous(breaks = seq(0, 21, by = 3)) +
  labs(title = "Speedrun Performance Improvement Over Time",
       subtitle = "Overall success rate across all intervals by day",
       x = "Day",
       y = "Success Rate") +
  theme_minimal(base_size = 13) +
  theme(plot.title = element_text(hjust = 0.5, face = "bold", size = 16),
        plot.subtitle = element_text(hjust = 0.5, size = 12, color = "gray30"),
        panel.grid.minor = element_blank(),
        axis.title = element_text(face = "bold"),
        legend.position = "right")
```

Models
```{r}
#Now that we've shown that there is improvement
# Model improvement over time on interval completion
cloglog_time = glm(Success ~ DayNum + factor(Interval), 
                   data = interval_data, 
                   family = binomial(link = "cloglog"))
summary(cloglog_time)

cloglog_full = glm(Success ~ DayNum * factor(Interval), 
                   data = interval_data, 
                   family = binomial(link = "cloglog"))

anova(cloglog_time, cloglog_full, test = "Chisq")
#saturated model is better so do stepwise to find best AIC

```

Stepwise
```{r}
# Null model (intercept only)
cloglog_null = glm(Success ~ 1, 
                   data = interval_data, 
                   family = binomial(link = "cloglog"))

# Forward stepwise selection
forward_model = step(cloglog_null, 
                     scope = list(lower = cloglog_null, upper = cloglog_full),
                     direction = "forward",
                     trace = 0)

# Backward stepwise selection
backward_model = step(cloglog_full,
                      direction = "backward",
                      trace = 0)

# Both directions stepwise selection
both_model = step(cloglog_null,
                  scope = list(lower = cloglog_null, upper = cloglog_full),
                  direction = "both",
                  trace = 0)

best_model = forward_model

summary(best_model)
#Best model is Success ~ factor(Interval) + DayNum + factor(Inveral):DayNum

```

Find if model is a good fit
```{r}
# Analyze best_model fit

cat("P-value:", deviance_gof, "\n")
cat("Interpretation: p >0.05 indicates good fit\n")

# 3. Pearson Chi-Square Test
pearson_resid = residuals(best_model, type = "pearson")
pearson_chisq = sum(pearson_resid^2)
pearson_pval = 1 - pchisq(pearson_chisq, best_model$df.residual)
cat("\nPearson Chi-Square Test:\n")
cat("Chi-Square:", pearson_chisq, "\n")
cat("P-value:", pearson_pval, "\n")

# 4. Hosmer-Lemeshow Test
library(ResourceSelection)
hl_test = hoslem.test(interval_data$Success, fitted(best_model), g = 10)
print(hl_test)
cat("Hosmer-Lemeshow: p >0.05 indicates good fit\n")

# 5. McFadden's Pseudo R-squared
null_dev = best_model$null.deviance
resid_dev = best_model$deviance
pseudo_r2 = 1 - (resid_dev / null_dev)
cat("\nMcFadden's Pseudo R-squared:", pseudo_r2, "\n")
cat("Interpretation: 0.2-0.4 = excellent fit\n")

# 6. Calculate VIF for multicollinearity (if applicable)
cat("\nVariance Inflation Factors:\n")
vif_values = vif(best_model)
print(vif_values)
cat("VIF < 10 indicates no serious multicollinearity\n")

# 7. GRAPHS

# Graph 3: Residuals by Interval
ggplot(interval_data, aes(x = factor(Interval), y = deviance_resid)) +
  geom_boxplot(fill = "lightblue", alpha = 0.7) +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(title = "Residuals by Interval",
       subtitle = "Checking if residuals vary by interval level",
       x = "Interval",
       y = "Deviance Residuals") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))
#This shows that the interaction term is fine, Interval 3,4,7 might have more to it that my model doesn't capture


# Graph 4: Residuals over Time
ggplot(interval_data, aes(x = DayNum, y = deviance_resid)) +
  geom_point(alpha = 0.5, color = "steelblue") +
  geom_smooth(method = "loess", se = TRUE, color = "darkblue") +
  geom_hline(yintercept = 0, color = "red", linetype = "dashed") +
  labs(title = "Residuals Over Time",
       subtitle = "Checking for temporal patterns",
       x = "Day",
       y = "Deviance Residuals") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

# 8. Influential Points
interval_data$cooks_d = cooks.distance(best_model)

# Graph 5: Cook's Distance
ggplot(interval_data, aes(x = 1:nrow(interval_data), y = cooks_d)) +
  geom_bar(stat = "identity", fill = "steelblue", alpha = 0.7) +
  geom_hline(yintercept = 4/nrow(interval_data), color = "red", 
             linetype = "dashed", linewidth = 1) +
  labs(title = "Cook's Distance - Influential Observations",
       subtitle = "Points above red line may be influential",
       x = "Observation Index",
       y = "Cook's Distance") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))

# 9. Summary Statistics
cat("\n=== MODEL FIT SUMMARY ===\n")
cat("AIC:", AIC(best_model), "\n")
cat("BIC:", BIC(best_model), "\n")
cat("Log-Likelihood:", logLik(best_model), "\n")
cat("Pseudo R-squared:", pseudo_r2, "\n")

```

Fitted vs Actual Graph
```{r}
# Better: Direct Actual vs Fitted comparison

# Create a dataset with both actual and fitted values
comparison_data = interval_data %>%
  dplyr::select(DayNum, Interval, Success, fitted_prob) %>%
  arrange(fitted_prob)

# Add observation index
comparison_data$obs_index = 1:nrow(comparison_data)

#Scatterplot with jitter (simpler, no select needed)
ggplot(interval_data, aes(x = fitted_prob, y = Success)) +
  geom_jitter(alpha = 0.3, width = 0, height = 0.05, color = "steelblue") +
  geom_smooth(method = "loess", se = TRUE, color = "red", linewidth = 1.5) +
  geom_abline(intercept = 0, slope = 1, linetype = "dashed", color = "darkgreen") +
  labs(title = "Actual vs Fitted Probabilities",
       subtitle = "Red line shows actual relationship, green line is perfect prediction",
       x = "Fitted Probability",
       y = "Actual Outcome (0 or 1)") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"))




# Option 2: ROC-style cumulative plot
interval_data_sorted = interval_data %>%
  arrange(fitted_prob) %>%
  mutate(
    obs_number = row_number(),
    cumulative_fitted = cummean(fitted_prob),
    cumulative_actual = cummean(Success)
  )

ggplot(interval_data_sorted, aes(x = obs_number)) +
  geom_line(aes(y = cumulative_actual, color = "Actual (Cumulative Avg)"), 
            linewidth = 1.2) +
  geom_line(aes(y = cumulative_fitted, color = "Fitted (Cumulative Avg)"), 
            linewidth = 1.2) +
  scale_color_manual(name = "Value",
                     values = c("Actual (Cumulative Avg)" = "red",
                               "Fitted (Cumulative Avg)" = "blue")) +
  labs(title = "Cumulative Average: Actual vs Fitted",
       subtitle = "Observations sorted by fitted probability",
       x = "Observation (sorted by fitted probability)",
       y = "Cumulative Average") +
  theme_minimal() +
  theme(plot.title = element_text(hjust = 0.5, face = "bold"),
        legend.position = "bottom")

```

Model to predict probability of each individual run
```{r}
# Initialize empty list
interval_models = list()

# Map intervals to their corresponding world record columns
interval_mapping = c(
  "1" = "W1_1",
  "2" = "W1_2", 
  "3" = "W4_1",
  "4" = "W4_2",
  "5" = "W8_1",
  "6" = "W8_2",
  "7" = "W8_3",
  "8" = "W8_4"
)

# Build models for intervals 1-7 (we're predicting interval 8/W8_4)
for (interval_num in 1:7) {
  
  cat("\n=== Processing Interval", interval_num, "(", interval_mapping[as.character(interval_num)], ") ===\n")
  
  # Filter data for this specific interval
  interval_subset = interval_data %>%
    filter(Interval == interval_num)
  
  cat("Number of observations:", nrow(interval_subset), "\n")
  cat("Success rate:", mean(interval_subset$Success), "\n")
  
  # Build cloglog model for this interval
  model = glm(Success ~ DayNum, 
              data = interval_subset,
              family = binomial(link = "cloglog"))
  
  # Store the model with the world column name as key
  world_col = interval_mapping[as.character(interval_num)]
  interval_models[[world_col]] = model
  
  cat("Model successfully fit!\n")
  print(summary(model))
}

# Now create predictions for each run in world_data
world_data = world_data %>%
  mutate(
    pred_W1_1 = predict(interval_models[["W1_1"]], 
                        newdata = data.frame(DayNum = DayNum), 
                        type = "response"),
    pred_W1_2 = predict(interval_models[["W1_2"]], 
                        newdata = data.frame(DayNum = DayNum), 
                        type = "response"),
    pred_W4_1 = predict(interval_models[["W4_1"]], 
                        newdata = data.frame(DayNum = DayNum), 
                        type = "response"),
    pred_W4_2 = predict(interval_models[["W4_2"]], 
                        newdata = data.frame(DayNum = DayNum), 
                        type = "response"),
    pred_W8_1 = predict(interval_models[["W8_1"]], 
                        newdata = data.frame(DayNum = DayNum), 
                        type = "response"),
    pred_W8_2 = predict(interval_models[["W8_2"]], 
                        newdata = data.frame(DayNum = DayNum), 
                        type = "response"),
    pred_W8_3 = predict(interval_models[["W8_3"]], 
                        newdata = data.frame(DayNum = DayNum), 
                        type = "response")
  )

# Calculate overall WR probability as product of all interval probabilities
world_data = world_data %>%
  mutate(
    pred_WR_prob = pred_W1_1 * pred_W1_2 * pred_W4_1 * pred_W4_2 * 
                   pred_W8_1 * pred_W8_2 * pred_W8_3
  )

# Now use this predicted WR probability in your final model
final_model = logistf(W8_4 ~ pred_WR_prob, data = world_data)

final_model_cloglog = glm(W8_4 ~ pred_WR_prob, 
                   data = world_data, 
                   family = binomial(link = "cloglog"))

summary(final_model)
summary(final_model_cloglog)
#should make final pred_WR remain deterministic based on predicted probabilities, because pred_WR_prob isn't stat significant

# Check the predictions
world_data %>%
  dplyr::select(DayNum, starts_with("pred_"), W8_4)
```






