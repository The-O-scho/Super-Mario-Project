color = "Actual WR") +
scale_color_manual(values = c("0" = "red", "1" = "green"),
labels = c("No WR", "WR")) +
theme_minimal()
# 7. ROC CURVE and AUC (measure of discrimination)
library(pROC)
roc_obj <- roc(data$W8_4, data$predicted_prob)
auc_value <- auc(roc_obj)
plot(roc_obj, main = paste("ROC Curve (AUC =", round(auc_value, 3), ")"))
cat("\nAUC (Area Under Curve):", auc_value, "\n")
cat("Interpretation: AUC > 0.7 = acceptable, > 0.8 = excellent\n")
# 9. Hosmer-Lemeshow test (goodness of fit)
library(ResourceSelection)
install.packages("ResourceSelection")
library(logistf)
library(ggplot2)
library(dplyr)
# Your model
firth_simple = logistf(W8_4 ~ success_rate, data = data)
summary(firth_simple)
# 1. Generate predictions for your existing data
data$predicted_prob <- predict(firth_simple, type = "response")
# 2. Look at predictions for different success rates
# Create a sequence of success rates from 0 to 1
new_data <- data.frame(success_rate = seq(0, 1, by = 0.1))
new_data$predicted_prob <- predict(firth_simple, newdata = new_data, type = "response")
print("Predicted probabilities of breaking world record:")
print(new_data)
# 3. Summary statistics of predictions
cat("\nPrediction Summary:\n")
cat("Min predicted probability:", min(data$predicted_prob), "\n")
cat("Max predicted probability:", max(data$predicted_prob), "\n")
cat("Mean predicted probability:", mean(data$predicted_prob), "\n")
cat("Actual world record rate:", mean(data$W8_4), "\n")
# 4. DIAGNOSTIC PLOT 1: Predicted probabilities vs actual outcomes
ggplot(data, aes(x = predicted_prob, fill = as.factor(W8_4))) +
geom_histogram(position = "identity", alpha = 0.6, bins = 30) +
labs(title = "Distribution of Predicted Probabilities",
x = "Predicted Probability of World Record",
y = "Count",
fill = "Actual WR") +
scale_fill_manual(values = c("0" = "red", "1" = "green"),
labels = c("No WR", "WR")) +
theme_minimal()
# 6. DIAGNOSTIC PLOT 3: Success rate vs probability curve
ggplot(data, aes(x = success_rate, y = predicted_prob)) +
geom_point(aes(color = as.factor(W8_4)), alpha = 0.5) +
geom_smooth(method = "loess", se = TRUE, color = "blue") +
labs(title = "Success Rate vs Predicted Probability",
x = "Success Rate (prior levels)",
y = "Predicted Probability of World Record",
color = "Actual WR") +
scale_color_manual(values = c("0" = "red", "1" = "green"),
labels = c("No WR", "WR")) +
theme_minimal()
# 7. ROC CURVE and AUC (measure of discrimination)
library(pROC)
roc_obj <- roc(data$W8_4, data$predicted_prob)
auc_value <- auc(roc_obj)
plot(roc_obj, main = paste("ROC Curve (AUC =", round(auc_value, 3), ")"))
cat("\nAUC (Area Under Curve):", auc_value, "\n")
cat("Interpretation: AUC > 0.7 = acceptable, > 0.8 = excellent\n")
# 9. Hosmer-Lemeshow test (goodness of fit)
library(ResourceSelection)
hl_test <- hoslem.test(data$W8_4, data$predicted_prob, g = 10)
print(hl_test)
cat("Hosmer-Lemeshow test: p >0.05 indicates good fit\n")
# 10. Example predictions for specific scenarios
example_scenarios <- data.frame(
scenario = c("Beginner", "Intermediate", "Advanced", "Expert"),
success_rate = c(0.2, 0.5, 0.8, 0.95)
)
example_scenarios$WR_probability <- predict(firth_simple,
newdata = example_scenarios,
type = "response")
cat("\n=== Example Predictions ===\n")
print(example_scenarios)
success_rate
# Create composite features
data = data %>%
mutate(
# Total successes in early levels (W1)
W1_total = W1_1 + W1_2,
# Total successes in mid levels (W4)
W4_total = W4_1 + W4_2,
# Total successes in late levels (W8, excluding outcome)
W8_prior = W8_1 + W8_2 + W8_3,
# Overall success rate up to W8_3
success_rate = (W1_1 + W1_2 + W4_1 + W4_2 + W8_1 + W8_2 + W8_3) / 7
)
success_rate
data
mean(data$success_rate)
library(logistf)
library(ggplot2)
library(dplyr)
# Your model
firth_simple = logistf(W8_4 ~ success_rate, data = data)
summary(firth_simple)
# 1. Generate predictions for your existing data
data$predicted_prob <- predict(firth_simple, type = "response")
# 2. Look at predictions for different success rates
# Create a sequence of success rates from 0 to 1
new_data <- data.frame(success_rate = seq(0, 1, by = 0.1))
new_data$predicted_prob <- predict(firth_simple, newdata = new_data, type = "response")
print("Predicted probabilities of breaking world record:")
print(new_data)
# 3. Summary statistics of predictions
cat("\nPrediction Summary:\n")
cat("Min predicted probability:", min(data$predicted_prob), "\n")
cat("Max predicted probability:", max(data$predicted_prob), "\n")
cat("Mean predicted probability:", mean(data$predicted_prob), "\n")
cat("Actual world record rate:", mean(data$W8_4), "\n")
# 4. DIAGNOSTIC PLOT 1: Predicted probabilities vs actual outcomes
ggplot(data, aes(x = predicted_prob, fill = as.factor(W8_4))) +
geom_histogram(position = "identity", alpha = 0.6, bins = 30) +
labs(title = "Distribution of Predicted Probabilities",
x = "Predicted Probability of World Record",
y = "Count",
fill = "Actual WR") +
scale_fill_manual(values = c("0" = "red", "1" = "green"),
labels = c("No WR", "WR")) +
theme_minimal()
# 6. DIAGNOSTIC PLOT 3: Success rate vs probability curve
ggplot(data, aes(x = success_rate, y = predicted_prob)) +
geom_point(aes(color = as.factor(W8_4)), alpha = 0.5) +
geom_smooth(method = "loess", se = TRUE, color = "blue") +
labs(title = "Success Rate vs Predicted Probability",
x = "Success Rate (prior levels)",
y = "Predicted Probability of World Record",
color = "Actual WR") +
scale_color_manual(values = c("0" = "red", "1" = "green"),
labels = c("No WR", "WR")) +
theme_minimal()
# 7. ROC CURVE and AUC (measure of discrimination)
library(pROC)
roc_obj <- roc(data$W8_4, data$predicted_prob)
auc_value <- auc(roc_obj)
plot(roc_obj, main = paste("ROC Curve (AUC =", round(auc_value, 3), ")"))
cat("\nAUC (Area Under Curve):", auc_value, "\n")
cat("Interpretation: AUC > 0.7 = acceptable, > 0.8 = excellent\n")
# 9. Hosmer-Lemeshow test (goodness of fit)
library(ResourceSelection)
hl_test <- hoslem.test(data$W8_4, data$predicted_prob, g = 10)
print(hl_test)
cat("Hosmer-Lemeshow test: p >0.05 indicates good fit\n")
# 10. Example predictions for specific scenarios
example_scenarios <- data.frame(
scenario = c("Beginner", "Intermediate", "Advanced", "Expert"),
success_rate = c(0.2, 0.5, 0.8, 0.95)
)
example_scenarios$WR_probability <- predict(firth_simple,
newdata = example_scenarios,
type = "response")
cat("\n=== Example Predictions ===\n")
print(example_scenarios)
print(hl_test)
library(ResourceSelection)
hl_test <- hoslem.test(data$W8_4, data$predicted_prob, g = 10)
print(hl_test)
cat("Hosmer-Lemeshow test: p >0.05 indicates good fit\n")
ggplot(data, aes(x = success_rate, y = predicted_prob)) +
geom_point(aes(color = as.factor(W8_4)), alpha = 0.5) +
geom_smooth(method = "loess", se = TRUE, color = "blue") +
labs(title = "Success Rate vs Predicted Probability",
x = "Success Rate (prior levels)",
y = "Predicted Probability of World Record",
color = "Actual WR") +
scale_color_manual(values = c("0" = "red", "1" = "green"),
labels = c("No WR", "WR")) +
theme_minimal()
library(logistf)
library(ggplot2)
library(dplyr)
# Your model
firth_simple = logistf(W8_4 ~ success_rate, data = data)
summary(firth_simple)
# 1. Generate predictions for your existing data
data$predicted_prob <- predict(firth_simple, type = "response")
# 2. Look at predictions for different success rates
# Create a sequence of success rates from 0 to 1
new_data <- data.frame(success_rate = seq(0, 1, by = 0.1))
new_data$predicted_prob <- predict(firth_simple, newdata = new_data, type = "response")
print("Predicted probabilities of breaking world record:")
print(new_data)
# 3. Summary statistics of predictions
cat("\nPrediction Summary:\n")
cat("Min predicted probability:", min(data$predicted_prob), "\n")
cat("Max predicted probability:", max(data$predicted_prob), "\n")
cat("Mean predicted probability:", mean(data$predicted_prob), "\n")
cat("Actual world record rate:", mean(data$W8_4), "\n")
# 4. DIAGNOSTIC PLOT 1: Predicted probabilities vs actual outcomes
ggplot(data, aes(x = predicted_prob, fill = as.factor(W8_4))) +
geom_histogram(position = "identity", alpha = 0.6, bins = 30) +
labs(title = "Distribution of Predicted Probabilities",
x = "Predicted Probability of World Record",
y = "Count",
fill = "Actual WR") +
scale_fill_manual(values = c("0" = "red", "1" = "green"),
labels = c("No WR", "WR")) +
theme_minimal()
# 5. DIAGNOSTIC PLOT 2: Calibration plot (predicted vs observed)
# Group predictions into bins
data$pred_bin <- cut(data$predicted_prob,
breaks = quantile(data$predicted_prob, probs = seq(0, 1, 0.1)),
include.lowest = TRUE)
ggplot(data, aes(x = success_rate, y = predicted_prob)) +
geom_point(aes(color = as.factor(W8_4)), alpha = 0.5) +
geom_smooth(method = "loess", se = TRUE, color = "blue") +
labs(title = "Success Rate vs Predicted Probability",
x = "Success Rate (prior levels)",
y = "Predicted Probability of World Record",
color = "Actual WR") +
scale_color_manual(values = c("0" = "red", "1" = "green"),
labels = c("No WR", "WR")) +
theme_minimal()
ggplot(data, aes(x = predicted_prob, fill = as.factor(W8_4))) +
geom_histogram(position = "identity", alpha = 0.6, bins = 30) +
labs(title = "Distribution of Predicted Probabilities",
x = "Predicted Probability of World Record",
y = "Count",
fill = "Actual WR") +
scale_fill_manual(values = c("0" = "red", "1" = "green"),
labels = c("No WR", "WR")) +
theme_minimal()
cat("\nPrediction Summary:\n")
cat("Min predicted probability:", min(data$predicted_prob), "\n")
cat("Max predicted probability:", max(data$predicted_prob), "\n")
cat("Mean predicted probability:", mean(data$predicted_prob), "\n")
cat("Actual world record rate:", mean(data$W8_4), "\n")
new_data
data
mean(data$predicted_class)
data
data["W1_1" = 1,]
data["W1_1 = 1",]
target_row <- data[
data$W1_1 == 1 &
data$W1_2 == 1 &
data$W4_1 == 1 &
data$W4_2 == 1 &
data$W8_1 == 1 &
data$W8_2 == 1 &
data$W8_3 == 1,
]
target_row <- data[
data$W1_1 == 1 &
data$W1_2 == 1 &
data$W4_1 == 1 &
data$W4_2 == 1 &
data$W8_1 == 1 &
data$W8_2 == 1 &
data$W8_3 == 1,
]
target_row
target_row <- data[
data$W1_1 == 1 &
data$W1_2 == 1 &
data$W4_1 == 1 &
data$W4_2 == 1 &
data$W8_1 == 1 &
data$W8_2 == 1 &
data$W8_3 == 1 &
data$W8_4 == 1,
]
target_row
target_row <- data[
data$W1_1 == 1 &
data$W1_2 == 1 &
data$W4_1 == 1 &
data$W4_2 == 1 &
data$W8_1 == 1 &
data$W8_2 == 1 &
data$W8_3 == 1,
]
target_row
zib_full = glmmTMB(
W8_4 ~ W1_1 + W1_2 + W4_1 + W4_2 + W8_1 + W8_2 + W8_3,        # count (binomial) part: intercept only
ziformula = ~ W1_1 + W1_2 + W4_1 + W4_2 + W8_1 + W8_2 + W8_3, # zero-inflation part: intercept only
family = binomial(link = logit),
data = data
)
summary(zib_full)
# Simpler model with composite features
firth_composite = logistf(W8_4 ~ W1_total + W4_total + W8_prior, data = data)
summary(firth_composite) #only W_8 prior matters maybe build up just previous w_8??? idk
# Or even simpler - just overall success rate
firth_simple = logistf(W8_4 ~ success_rate, data = data)
summary(firth_simple) #finally a significant p-val in just using success rate
data
data
target_row = data[
data$W1_1 == 1 &
data$W1_2 == 1 &
data$W4_1 == 1 &
data$W4_2 == 1 &
data$W8_1 == 1 &
data$W8_2 == 1 &
data$W8_3 == 1,
]
target_row
summary(zib_full)
print(hl_test)
cat("Hosmer-Lemeshow test: p >0.05 indicates good fit\n")
print(hl_test)
#Read in data (data is ordered)
data = read.csv("Nifski Ordered.csv")
glimpse(data)
#Read in data (data is ordered)
data = read.csv("Nifski Ordered.csv")
# Create composite features
data = data %>%
mutate(
# Overall success rate up to W8_3
success_rate = (W1_1 + W1_2 + W4_1 + W4_2 + W8_1 + W8_2 + W8_3) / 7
)
glimpse(data)
data
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE,
fig.width = 6, fig.height = 4)
library(tidyverse)
library(knitr)
library(readxl)
library(MASS)
library(dplyr)
library(car)
library(broom)
library(GGally)
library(glmmTMB)
library(logistf)
library(ggplot2)
# 7. ROC CURVE and AUC (measure of discrimination)
library(pROC)
roc_obj = roc(data$W8_4, data$predicted_prob)
firth_8_4 = logistf(W8_4 ~ W1_1 + W1_2 + W4_1 + W4_2 + W8_1 + W8_2 + W8_3,
data = data)
summary(firth_8_4)
firth_simple = logistf(W8_4 ~ success_rate, data = data)
summary(firth_simple) #finally a significant p-val in just using success rate
firth_simple = logistf(W8_4 ~ success_rate, data = data)
summary(firth_simple)
# 1. Generate predictions for your existing data
data$predicted_prob = predict(firth_simple, type = "response")
# 2. Look at predictions for different success rates
# Create a sequence of success rates from 0 to 1
new_data = data.frame(success_rate = seq(0, 1, by = 0.1))
new_data$predicted_prob = predict(firth_simple, newdata = new_data, type = "response")
print("Predicted probabilities of breaking world record:")
print(new_data)
# 3. Summary statistics of predictions
cat("\nPrediction Summary:\n")
cat("Min predicted probability:", min(data$predicted_prob), "\n")
cat("Max predicted probability:", max(data$predicted_prob), "\n")
cat("Mean predicted probability:", mean(data$predicted_prob), "\n")
cat("Actual world record rate:", mean(data$W8_4), "\n")
# 4. DIAGNOSTIC PLOT 1: Predicted probabilities vs actual outcomes
ggplot(data, aes(x = predicted_prob, fill = as.factor(W8_4))) +
geom_histogram(position = "identity", alpha = 0.6, bins = 30) +
labs(title = "Distribution of Predicted Probabilities",
x = "Predicted Probability of World Record",
y = "Count",
fill = "Actual WR") +
scale_fill_manual(values = c("0" = "red", "1" = "green"),
labels = c("No WR", "WR")) +
theme_minimal()
# 6. DIAGNOSTIC PLOT 3: Success rate vs probability curve
ggplot(data, aes(x = success_rate, y = predicted_prob)) +
geom_point(aes(color = as.factor(W8_4)), alpha = 0.5) +
geom_smooth(method = "loess", se = TRUE, color = "blue") +
labs(title = "Success Rate vs Predicted Probability",
x = "Success Rate (prior levels)",
y = "Predicted Probability of World Record",
color = "Actual WR") +
scale_color_manual(values = c("0" = "red", "1" = "green"),
labels = c("No WR", "WR")) +
theme_minimal()
# 7. ROC CURVE and AUC (measure of discrimination)
library(pROC)
roc_obj = roc(data$W8_4, data$predicted_prob)
auc_value = auc(roc_obj)
plot(roc_obj, main = paste("ROC Curve (AUC =", round(auc_value, 3), ")"))
cat("\nAUC (Area Under Curve):", auc_value, "\n")
cat("Interpretation: AUC > 0.7 = acceptable, > 0.8 = excellent\n")
# 9. Hosmer-Lemeshow test (goodness of fit)
library(ResourceSelection)
hl_test = hoslem.test(data$W8_4, data$predicted_prob, g = 10)
print(hl_test)
cat("Hosmer-Lemeshow test: p >0.05 indicates good fit\n")
# 10. Example predictions for specific scenarios
example_scenarios = data.frame(
scenario = c("Beginner", "Intermediate", "Advanced", "Expert"),
success_rate = c(0.2, 0.5, 0.8, 0.95)
)
example_scenarios$WR_probability = predict(firth_simple,
newdata = example_scenarios,
type = "response")
cat("\n Example Predictions \n")
print(example_scenarios)
target_row = data[
data$W1_1 == 1 &
data$W1_2 == 1 &
data$W4_1 == 1 &
data$W4_2 == 1 &
data$W8_1 == 1 &
data$W8_2 == 1 &
data$W8_3 == 1,
]
target_row
library(pROC)
roc_obj = roc(data$W8_4, data$predicted_prob)
auc_value = auc(roc_obj)
plot(roc_obj, main = paste("ROC Curve (AUC =", round(auc_value, 3), ")"))
cat("\nAUC (Area Under Curve):", auc_value, "\n")
cat("Interpretation: AUC > 0.7 = acceptable, > 0.8 = excellent\n")
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE,
fig.width = 6, fig.height = 4)
library(tidyverse)
library(knitr)
library(readxl)
library(MASS)
library(dplyr)
library(car)
library(broom)
library(GGally)
library(glmmTMB)
library(logistf)
library(ggplot2)
library(ResourceSelection)
# 6. DIAGNOSTIC PLOT 3: Success rate vs probability curve
ggplot(data, aes(x = success_rate, y = predicted_prob)) +
geom_point(aes(color = as.factor(W8_4)), alpha = 0.5) +
geom_smooth(method = "loess", se = TRUE, color = "blue") +
labs(title = "Success Rate vs Predicted Probability",
x = "Success Rate (prior levels)",
y = "Predicted Probability of World Record",
color = "Actual WR") +
scale_color_manual(values = c("0" = "red", "1" = "green"),
labels = c("No WR", "WR")) +
theme_minimal()
# 4. DIAGNOSTIC PLOT 1: Predicted probabilities vs actual outcomes
ggplot(data, aes(x = predicted_prob, fill = as.factor(W8_4))) +
geom_histogram(position = "identity", alpha = 0.6, bins = 30) +
labs(title = "Distribution of Predicted Probabilities",
x = "Predicted Probability of World Record",
y = "Count",
fill = "Actual WR") +
scale_fill_manual(values = c("0" = "red", "1" = "green"),
labels = c("No WR", "WR")) +
theme_minimal()
print(new_data)
firth_simple = logistf(W8_4 ~ success_rate, data = data)
summary(firth_simple)
# 1. Generate predictions for your existing data
data$predicted_prob = predict(firth_simple, type = "response")
# 2. DIAGNOSTIC PLOT 3: Success rate vs probability curve
ggplot(data, aes(x = success_rate, y = predicted_prob)) +
geom_point(aes(color = as.factor(W8_4)), alpha = 0.5) +
geom_smooth(method = "loess", se = TRUE, color = "blue") +
labs(title = "Success Rate vs Predicted Probability",
x = "Success Rate (prior levels)",
y = "Predicted Probability of World Record",
color = "Actual WR") +
scale_color_manual(values = c("0" = "red", "1" = "green"),
labels = c("No WR", "WR")) +
theme_minimal()
# 4.goodness of fit
hl_test = hoslem.test(data$W8_4, data$predicted_prob, g = 10)
print(hl_test)
cat("Hosmer-Lemeshow test: p >0.05 indicates good fit\n")
cat("\n Example Predictions \n")
print(example_scenarios)
target_row = data[
data$W1_1 == 1 &
data$W1_2 == 1 &
data$W4_1 == 1 &
data$W4_2 == 1 &
data$W8_1 == 1 &
data$W8_2 == 1 &
data$W8_3 == 1,
]
target_row
summary(firth_simple) #finally a significant p-val in just using success rate
zib_full_2 = glmmTMB(
W8_4 ~ success_rate,        # count (binomial) part: intercept only
ziformula = ~ success_rate, # zero-inflation part: intercept only
family = binomial(link = logit),
data = data
)
summary(zib_full_2)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE,
fig.width = 6, fig.height = 4)
library(tidyverse)
library(knitr)
library(readxl)
library(MASS)
library(dplyr)
library(car)
library(broom)
library(GGally)
library(glmmTMB)
library(logistf)
library(ggplot2)
library(ResourceSelection)
# Create composite features
data = data %>%
mutate(
# Overall success rate up to W8_3
success_rate = (W1_1 + W1_2 + W4_1 + W4_2 + W8_1 + W8_2 + W8_3) / 7
)
#Read in data (data is ordered)
data = read.csv("Nifski Ordered.csv")
data
